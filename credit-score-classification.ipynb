{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-27T19:15:46.734201Z",
     "iopub.status.busy": "2025-08-27T19:15:46.733167Z",
     "iopub.status.idle": "2025-08-27T19:15:48.271926Z",
     "shell.execute_reply": "2025-08-27T19:15:48.270958Z",
     "shell.execute_reply.started": "2025-08-27T19:15:46.734162Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/credit-score-classification/train.csv\n",
      "/kaggle/input/credit-score-classification/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:44:25.305943Z",
     "iopub.status.busy": "2025-08-16T09:44:25.305322Z",
     "iopub.status.idle": "2025-08-16T09:44:25.310071Z",
     "shell.execute_reply": "2025-08-16T09:44:25.308976Z",
     "shell.execute_reply.started": "2025-08-16T09:44:25.305914Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Remove Warning\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:44:31.504376Z",
     "iopub.status.busy": "2025-08-16T09:44:31.504093Z",
     "iopub.status.idle": "2025-08-16T09:44:32.653915Z",
     "shell.execute_reply": "2025-08-16T09:44:32.653088Z",
     "shell.execute_reply.started": "2025-08-16T09:44:31.504351Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Importing dataset\n",
    "credit_df = pd.read_csv('/kaggle/input/credit-score-classification/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:44:32.679528Z",
     "iopub.status.busy": "2025-08-16T09:44:32.678787Z",
     "iopub.status.idle": "2025-08-16T09:44:32.685059Z",
     "shell.execute_reply": "2025-08-16T09:44:32.684372Z",
     "shell.execute_reply.started": "2025-08-16T09:44:32.679498Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:44:35.415958Z",
     "iopub.status.busy": "2025-08-16T09:44:35.415651Z",
     "iopub.status.idle": "2025-08-16T09:44:35.421417Z",
     "shell.execute_reply": "2025-08-16T09:44:35.420800Z",
     "shell.execute_reply.started": "2025-08-16T09:44:35.415933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:44:36.848144Z",
     "iopub.status.busy": "2025-08-16T09:44:36.847863Z",
     "iopub.status.idle": "2025-08-16T09:44:36.888033Z",
     "shell.execute_reply": "2025-08-16T09:44:36.887297Z",
     "shell.execute_reply.started": "2025-08-16T09:44:36.848121Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Datatypes, Missing Data,Finding Categorical Col, and Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:44:42.000384Z",
     "iopub.status.busy": "2025-08-16T09:44:42.000105Z",
     "iopub.status.idle": "2025-08-16T09:44:42.126352Z",
     "shell.execute_reply": "2025-08-16T09:44:42.125395Z",
     "shell.execute_reply.started": "2025-08-16T09:44:42.000361Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:44:44.031752Z",
     "iopub.status.busy": "2025-08-16T09:44:44.031145Z",
     "iopub.status.idle": "2025-08-16T09:44:44.038152Z",
     "shell.execute_reply": "2025-08-16T09:44:44.037445Z",
     "shell.execute_reply.started": "2025-08-16T09:44:44.031725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Viewing all type of data we have\n",
    "credit_df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:44:45.518035Z",
     "iopub.status.busy": "2025-08-16T09:44:45.517741Z",
     "iopub.status.idle": "2025-08-16T09:44:45.523971Z",
     "shell.execute_reply": "2025-08-16T09:44:45.523237Z",
     "shell.execute_reply.started": "2025-08-16T09:44:45.518011Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# find categorical Columns and put that into a \n",
    "\n",
    "categorical = [var for var in credit_df.columns if credit_df[var].dtype=='O']\n",
    "\n",
    "print('There are {} categorical variables\\n'.format(len(categorical)))\n",
    "\n",
    "print('The categorical variables are :\\n\\n', categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:44:47.722052Z",
     "iopub.status.busy": "2025-08-16T09:44:47.721770Z",
     "iopub.status.idle": "2025-08-16T09:44:47.735785Z",
     "shell.execute_reply": "2025-08-16T09:44:47.735092Z",
     "shell.execute_reply.started": "2025-08-16T09:44:47.722031Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df['Credit_Score'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:46:42.872282Z",
     "iopub.status.busy": "2025-08-16T09:46:42.871557Z",
     "iopub.status.idle": "2025-08-16T09:46:42.901792Z",
     "shell.execute_reply": "2025-08-16T09:46:42.900831Z",
     "shell.execute_reply.started": "2025-08-16T09:46:42.872254Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df[categorical].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:44:55.861496Z",
     "iopub.status.busy": "2025-08-16T09:44:55.860937Z",
     "iopub.status.idle": "2025-08-16T09:44:55.866480Z",
     "shell.execute_reply": "2025-08-16T09:44:55.865637Z",
     "shell.execute_reply.started": "2025-08-16T09:44:55.861450Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:46:46.160890Z",
     "iopub.status.busy": "2025-08-16T09:46:46.160370Z",
     "iopub.status.idle": "2025-08-16T09:46:46.174166Z",
     "shell.execute_reply": "2025-08-16T09:46:46.173529Z",
     "shell.execute_reply.started": "2025-08-16T09:46:46.160864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df['Month'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:46:47.901922Z",
     "iopub.status.busy": "2025-08-16T09:46:47.901384Z",
     "iopub.status.idle": "2025-08-16T09:46:47.911158Z",
     "shell.execute_reply": "2025-08-16T09:46:47.910429Z",
     "shell.execute_reply.started": "2025-08-16T09:46:47.901900Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df['Month'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:46:49.974666Z",
     "iopub.status.busy": "2025-08-16T09:46:49.974112Z",
     "iopub.status.idle": "2025-08-16T09:46:50.305853Z",
     "shell.execute_reply": "2025-08-16T09:46:50.305180Z",
     "shell.execute_reply.started": "2025-08-16T09:46:49.974641Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for col in credit_df:\n",
    "    print(f\"Value counts for '{col}':\")\n",
    "    print(credit_df[col].value_counts())\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:46:56.166001Z",
     "iopub.status.busy": "2025-08-16T09:46:56.165691Z",
     "iopub.status.idle": "2025-08-16T09:46:56.344415Z",
     "shell.execute_reply": "2025-08-16T09:46:56.343625Z",
     "shell.execute_reply.started": "2025-08-16T09:46:56.165977Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for col in credit_df:\n",
    "    print(f\"Value counts for '{col}':\")\n",
    "    print(credit_df[col].nunique())\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:47:01.074065Z",
     "iopub.status.busy": "2025-08-16T09:47:01.073696Z",
     "iopub.status.idle": "2025-08-16T09:47:01.090721Z",
     "shell.execute_reply": "2025-08-16T09:47:01.089887Z",
     "shell.execute_reply.started": "2025-08-16T09:47:01.074032Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df['Type_of_Loan'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:47:05.757396Z",
     "iopub.status.busy": "2025-08-16T09:47:05.756905Z",
     "iopub.status.idle": "2025-08-16T09:47:05.820410Z",
     "shell.execute_reply": "2025-08-16T09:47:05.819770Z",
     "shell.execute_reply.started": "2025-08-16T09:47:05.757371Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Changing the datatype of the above mentioned columns to category\n",
    "\n",
    "credit_df.Month = credit_df.Month.astype('category')\n",
    "credit_df.Occupation = credit_df.Occupation.astype('category')\n",
    "credit_df.Type_of_Loan = credit_df.Type_of_Loan.astype('category')\n",
    "credit_df.Credit_Mix = credit_df.Credit_Mix.astype('category')\n",
    "credit_df.Payment_of_Min_Amount = credit_df.Payment_of_Min_Amount.astype('category')\n",
    "credit_df.Payment_Behaviour = credit_df.Payment_Behaviour.astype('category')\n",
    "credit_df.Credit_Score = credit_df.Credit_Score.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:47:07.312002Z",
     "iopub.status.busy": "2025-08-16T09:47:07.311698Z",
     "iopub.status.idle": "2025-08-16T09:47:07.402041Z",
     "shell.execute_reply": "2025-08-16T09:47:07.401207Z",
     "shell.execute_reply.started": "2025-08-16T09:47:07.311978Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:47:10.087554Z",
     "iopub.status.busy": "2025-08-16T09:47:10.086802Z",
     "iopub.status.idle": "2025-08-16T09:47:10.123761Z",
     "shell.execute_reply": "2025-08-16T09:47:10.123064Z",
     "shell.execute_reply.started": "2025-08-16T09:47:10.087504Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df['Age'].astype(str).str.contains('_').any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:47:11.887001Z",
     "iopub.status.busy": "2025-08-16T09:47:11.886273Z",
     "iopub.status.idle": "2025-08-16T09:47:11.952253Z",
     "shell.execute_reply": "2025-08-16T09:47:11.951479Z",
     "shell.execute_reply.started": "2025-08-16T09:47:11.886974Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df[credit_df['Age'].astype(str).str.contains('_')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Columns type we need to Change: `Age`,`Annual_Income`,`Num_of_Loan`,`Num_of_Delayed_Payment `,`Changed_Credit_Limit`,\n",
    "`Outstanding_Debt`,`Amount_invested_monthly`,`Monthly_Balance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:47:16.185841Z",
     "iopub.status.busy": "2025-08-16T09:47:16.185228Z",
     "iopub.status.idle": "2025-08-16T09:47:16.838331Z",
     "shell.execute_reply": "2025-08-16T09:47:16.837514Z",
     "shell.execute_reply.started": "2025-08-16T09:47:16.185808Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Function to remove leading/trailing underscores and return cleaned value\n",
    "def removeUnderscore(value):\n",
    "    first_index = 0\n",
    "    last_index = len(value) - 1\n",
    "\n",
    "    while first_index <= last_index:\n",
    "        if value[first_index] == '_':\n",
    "            first_index += 1\n",
    "        if value[last_index] == '_':\n",
    "            last_index -= 1\n",
    "\n",
    "        # Break when there are no underscores in the substring\n",
    "        if '_' not in value[first_index : last_index + 1]:\n",
    "            cleaned_value = value[first_index : last_index + 1]\n",
    "            return 0 if cleaned_value == '' else cleaned_value\n",
    "\n",
    "\n",
    "# Function to clean and convert object-type columns to float\n",
    "def un_clean(columns):\n",
    "    for column in columns:\n",
    "        # Convert all values to strings\n",
    "        raw_data = [str(value) for value in list(credit_df[column])]\n",
    "        cleaned_data = []\n",
    "\n",
    "        for value in raw_data:\n",
    "            if value.lower() == 'nan':\n",
    "                cleaned_data.append(float('nan'))\n",
    "            else:\n",
    "                cleaned_value = removeUnderscore(value)\n",
    "                cleaned_data.append(float(cleaned_value))\n",
    "\n",
    "        credit_df[column] = cleaned_data\n",
    "\n",
    "\n",
    "# Apply to selected columns\n",
    "un_clean([\n",
    "    'Age', \n",
    "    'Annual_Income', \n",
    "    'Num_of_Loan', \n",
    "    'Num_of_Delayed_Payment', \n",
    "    'Outstanding_Debt', \n",
    "    'Changed_Credit_Limit',\n",
    "    'Amount_invested_monthly', \n",
    "    'Monthly_Balance'\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:47:19.423193Z",
     "iopub.status.busy": "2025-08-16T09:47:19.422601Z",
     "iopub.status.idle": "2025-08-16T09:47:19.469058Z",
     "shell.execute_reply": "2025-08-16T09:47:19.468377Z",
     "shell.execute_reply.started": "2025-08-16T09:47:19.423169Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Columns type we need to Change: `Age`,`Annual_Income`,`Num_of_Loan`,`Num_of_Delayed_Payment `,`Changed_Credit_Limit`,\n",
    "`Outstanding_Debt`,`Amount_invested_monthly`,`Monthly_Balance` Now we can see that all this column is changes object to float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now We can see there are missing values we have in some of the columns that we need to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:47:24.476349Z",
     "iopub.status.busy": "2025-08-16T09:47:24.476075Z",
     "iopub.status.idle": "2025-08-16T09:47:24.514522Z",
     "shell.execute_reply": "2025-08-16T09:47:24.513660Z",
     "shell.execute_reply.started": "2025-08-16T09:47:24.476328Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Missing Values\n",
    "credit_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:47:26.911096Z",
     "iopub.status.busy": "2025-08-16T09:47:26.910812Z",
     "iopub.status.idle": "2025-08-16T09:47:26.950312Z",
     "shell.execute_reply": "2025-08-16T09:47:26.949527Z",
     "shell.execute_reply.started": "2025-08-16T09:47:26.911074Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Missing data by columns in the dataset Order Wise\n",
    "\n",
    "credit_df.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:47:28.956933Z",
     "iopub.status.busy": "2025-08-16T09:47:28.956639Z",
     "iopub.status.idle": "2025-08-16T09:47:28.997311Z",
     "shell.execute_reply": "2025-08-16T09:47:28.996649Z",
     "shell.execute_reply.started": "2025-08-16T09:47:28.956911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "missing = credit_df.isnull().sum()\n",
    "missing_percent = (missing / len(credit_df)) * 100\n",
    "missing_table = pd.DataFrame({'Missing Values': missing, 'Percent (%)': missing_percent})\n",
    "missing_table = missing_table[missing_table['Missing Values'] > 0].sort_values(by='Percent (%)', ascending=False)\n",
    "print(missing_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above data, we observe that the columns `Monthly_Inhand_Salary`, `Type_of_Loan`, `Name`, `Credit_History_Age`, `Num_of_Delayed_Payment`, `Amount_invested_monthly`, `Num_Credit_Inquiries`, and `Monthly_Balance` contain missing values. Next, we will analyze the distribution of these missing values to determine whether they are clustered in specific sections or scattered throughout the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only Missing values Bar Chart repreesentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:47:32.229794Z",
     "iopub.status.busy": "2025-08-16T09:47:32.229044Z",
     "iopub.status.idle": "2025-08-16T09:47:35.048099Z",
     "shell.execute_reply": "2025-08-16T09:47:35.047304Z",
     "shell.execute_reply.started": "2025-08-16T09:47:32.229768Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "missing_df = credit_df.isnull().sum().reset_index()\n",
    "missing_df.columns = ['column', 'missing_count']\n",
    "missing_df = missing_df[missing_df['missing_count'] > 0]\n",
    "\n",
    "fig = px.bar(missing_df, x='column', y='missing_count',\n",
    "             title='Missing Values per Column',\n",
    "             color='missing_count',\n",
    "             color_continuous_scale='sunset')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:47:40.474208Z",
     "iopub.status.busy": "2025-08-16T09:47:40.473942Z",
     "iopub.status.idle": "2025-08-16T09:47:41.301527Z",
     "shell.execute_reply": "2025-08-16T09:47:41.300841Z",
     "shell.execute_reply.started": "2025-08-16T09:47:40.474188Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Importing seaborn & matplotlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:47:42.591683Z",
     "iopub.status.busy": "2025-08-16T09:47:42.590840Z",
     "iopub.status.idle": "2025-08-16T09:47:45.931886Z",
     "shell.execute_reply": "2025-08-16T09:47:45.930899Z",
     "shell.execute_reply.started": "2025-08-16T09:47:42.591657Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Visual representation of the missing data in the dataset\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(credit_df.isnull(), cbar=False, cmap=\"tab10\")\n",
    "plt.title(\"Heatmap of Missing Values\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:48:42.919218Z",
     "iopub.status.busy": "2025-08-16T09:48:42.918841Z",
     "iopub.status.idle": "2025-08-16T09:48:43.916072Z",
     "shell.execute_reply": "2025-08-16T09:48:43.915250Z",
     "shell.execute_reply.started": "2025-08-16T09:48:42.919191Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compute the null correlation matrix\n",
    "null_corr = credit_df.isnull().corr()\n",
    "\n",
    "# Plot with a diverging color palette\n",
    "plt.figure(figsize=(20, 12))\n",
    "sns.heatmap(null_corr, cmap='coolwarm', annot=True, linewidths=0.5, linecolor='gray')\n",
    "plt.title(\"Correlation of Missing Values\", fontsize=14)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From the above data, we can see that the missing values in the data are scattered, not clustered at a single place.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:48:45.087073Z",
     "iopub.status.busy": "2025-08-16T09:48:45.086783Z",
     "iopub.status.idle": "2025-08-16T09:48:45.191320Z",
     "shell.execute_reply": "2025-08-16T09:48:45.190416Z",
     "shell.execute_reply.started": "2025-08-16T09:48:45.087053Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Summary statistics of the numerical columns in the dataset\n",
    "\n",
    "credit_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above summary statistics, we can see that there are `outliers` present in the data. We will take care of these in the next sections(Preprocessing).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2 Feature Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.1 Categorical variable - Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:48:52.524697Z",
     "iopub.status.busy": "2025-08-16T09:48:52.524058Z",
     "iopub.status.idle": "2025-08-16T09:48:52.532790Z",
     "shell.execute_reply": "2025-08-16T09:48:52.532055Z",
     "shell.execute_reply.started": "2025-08-16T09:48:52.524673Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Value counts of the column - Occupation\n",
    "\n",
    "occupation_count = credit_df['Occupation'].value_counts(dropna = False)\n",
    "occupation_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the parameter `dropna=False` tells pandas to include missing values (NaN) in the count.\n",
    "\n",
    "ðŸ” Explanation:\n",
    "By default, value_counts() ignores NaN values.\n",
    "\n",
    "If you want to see how many missing values are present in the column along with other values, use dropna=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:48:58.401838Z",
     "iopub.status.busy": "2025-08-16T09:48:58.401163Z",
     "iopub.status.idle": "2025-08-16T09:48:58.854371Z",
     "shell.execute_reply": "2025-08-16T09:48:58.853647Z",
     "shell.execute_reply.started": "2025-08-16T09:48:58.401813Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Bar graph showing the value counts of the column - Occupation\n",
    "\n",
    "sns.set(rc = {'figure.figsize': (20, 10)})\n",
    "sns.barplot(x=occupation_count.index, y=occupation_count.values)\n",
    "plt.title('Bar graph showing the value counts of the column - Occupation')\n",
    "plt.ylabel('Count', fontsize = 12)\n",
    "plt.xlabel('Occupation', fontsize = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:49:01.757785Z",
     "iopub.status.busy": "2025-08-16T09:49:01.757215Z",
     "iopub.status.idle": "2025-08-16T09:49:01.763447Z",
     "shell.execute_reply": "2025-08-16T09:49:01.762623Z",
     "shell.execute_reply.started": "2025-08-16T09:49:01.757762Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df['Occupation'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, we can see that most of the jobs are 'unnamed'.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:49:04.016326Z",
     "iopub.status.busy": "2025-08-16T09:49:04.015448Z",
     "iopub.status.idle": "2025-08-16T09:49:04.021318Z",
     "shell.execute_reply": "2025-08-16T09:49:04.020637Z",
     "shell.execute_reply.started": "2025-08-16T09:49:04.016301Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "occupation_count.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:49:05.756814Z",
     "iopub.status.busy": "2025-08-16T09:49:05.756444Z",
     "iopub.status.idle": "2025-08-16T09:49:05.763109Z",
     "shell.execute_reply": "2025-08-16T09:49:05.762315Z",
     "shell.execute_reply.started": "2025-08-16T09:49:05.756791Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "occupation_count.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:00:12.728590Z",
     "iopub.status.busy": "2025-08-16T10:00:12.728262Z",
     "iopub.status.idle": "2025-08-16T10:00:12.762406Z",
     "shell.execute_reply": "2025-08-16T10:00:12.761629Z",
     "shell.execute_reply.started": "2025-08-16T10:00:12.728565Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Set the display option to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Now, filter and display your DataFrame\n",
    "good_credit_df = credit_df[credit_df['Credit_Score'] == 'Good']\n",
    "\n",
    "# This will now print all the columns without skipping any\n",
    "good_credit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:55:05.785731Z",
     "iopub.status.busy": "2025-08-16T09:55:05.784956Z",
     "iopub.status.idle": "2025-08-16T09:55:09.233326Z",
     "shell.execute_reply": "2025-08-16T09:55:09.232487Z",
     "shell.execute_reply.started": "2025-08-16T09:55:05.785704Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Distribution of Credit_Score for each Occupation\n",
    "\n",
    "sns.catplot(x='Credit_Score', \n",
    "            col='Occupation', \n",
    "            data=credit_df, \n",
    "            kind='count', \n",
    "            col_wrap=4, \n",
    "            height=4, \n",
    "            aspect=1.2)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By observing we can see that all have the `Standard` Credit_Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.2 Categorical variable - Type of Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:55:09.605531Z",
     "iopub.status.busy": "2025-08-16T09:55:09.604898Z",
     "iopub.status.idle": "2025-08-16T09:55:09.613312Z",
     "shell.execute_reply": "2025-08-16T09:55:09.612550Z",
     "shell.execute_reply.started": "2025-08-16T09:55:09.605496Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "index_values = ~credit_df['Type_of_Loan'].isnull().values\n",
    "loan_type_data = list(credit_df['Type_of_Loan'][index_values])\n",
    "# loan_type_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal of Below Code:Count how many times each type of loan appears across all customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:55:13.211489Z",
     "iopub.status.busy": "2025-08-16T09:55:13.210889Z",
     "iopub.status.idle": "2025-08-16T09:55:13.414070Z",
     "shell.execute_reply": "2025-08-16T09:55:13.413232Z",
     "shell.execute_reply.started": "2025-08-16T09:55:13.211436Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Create a dictionary to store the counts of all the various loan types\n",
    "\n",
    "loan_type_dict = dict()\n",
    "for value in loan_type_data:\n",
    "    values = value.split(',')\n",
    "    for each_value in values:\n",
    "        loan_type = each_value.strip(' ')\n",
    "        if 'and' in loan_type:\n",
    "            loan_type = loan_type[4 : ]\n",
    "        if loan_type in loan_type_dict:\n",
    "            loan_type_dict[loan_type] += 1 # This is for Exsisting one Counting\n",
    "        else:\n",
    "            loan_type_dict[loan_type] = 1  # This is for new one \n",
    "\n",
    "loan_type_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T09:55:15.350264Z",
     "iopub.status.busy": "2025-08-16T09:55:15.349755Z",
     "iopub.status.idle": "2025-08-16T09:55:15.841293Z",
     "shell.execute_reply": "2025-08-16T09:55:15.840625Z",
     "shell.execute_reply.started": "2025-08-16T09:55:15.350238Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Bar graph showing the counts of the column - Type_of_Loan\n",
    "\n",
    "sns.set(rc = {'figure.figsize': (15, 10)})\n",
    "sns.barplot(x=list(loan_type_dict.keys()), y=list(loan_type_dict.values()))\n",
    "plt.title('Bar graph showing the counts of the column - Type_of_Loan')\n",
    "plt.ylabel('Count', fontsize = 12)\n",
    "plt.xlabel('Type_of_Loan', fontsize = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, we can see that the `Payday Loans` and `Credit-Builder Loans` are the highest occurrences of loans among all the other loans.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.3 Categorical variable - Credit_MIxÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:02:04.946752Z",
     "iopub.status.busy": "2025-08-16T10:02:04.946014Z",
     "iopub.status.idle": "2025-08-16T10:02:04.954388Z",
     "shell.execute_reply": "2025-08-16T10:02:04.953785Z",
     "shell.execute_reply.started": "2025-08-16T10:02:04.946720Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Value counts of the column - Credit_Mix\n",
    "\n",
    "credit_mix_count = credit_df['Credit_Mix'].value_counts(dropna = False)\n",
    "credit_mix_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:02:06.772157Z",
     "iopub.status.busy": "2025-08-16T10:02:06.771887Z",
     "iopub.status.idle": "2025-08-16T10:02:06.966887Z",
     "shell.execute_reply": "2025-08-16T10:02:06.966067Z",
     "shell.execute_reply.started": "2025-08-16T10:02:06.772138Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Bar graph showing the value counts of the column - Credit_Mix\n",
    "\n",
    "sns.set(rc = {'figure.figsize': (6, 6)})\n",
    "sns.barplot(x=credit_mix_count.index, y=credit_mix_count.values, alpha = 0.8)\n",
    "plt.title('Bar graph showing the value counts of the column - Credit_Mix')\n",
    "plt.ylabel('Number of Occurrences', fontsize = 12)\n",
    "plt.xlabel('Credit Mix', fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, we can see that most of the customers have a `Standard` credit mix.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:02:10.287985Z",
     "iopub.status.busy": "2025-08-16T10:02:10.287678Z",
     "iopub.status.idle": "2025-08-16T10:02:11.302964Z",
     "shell.execute_reply": "2025-08-16T10:02:11.302165Z",
     "shell.execute_reply.started": "2025-08-16T10:02:10.287962Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Distribution of Credit_Score for each Credit_Mix\n",
    "\n",
    "sns.catplot(\n",
    "    x='Credit_Score',\n",
    "    col='Credit_Mix',\n",
    "    data=credit_df,\n",
    "    kind='count',\n",
    "    col_wrap=3,\n",
    "    height=4,        # size of each small plot\n",
    "    aspect=1         # width-to-height ratio\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â€œFrom the above graphs, we can observe a strong relationship between `Credit_Mix` and `Credit_Score`. For example, when Credit_Mix is `Bad`, the majority of Credit_Score values are `Poor`. Similarly, a `Good` Credit_Mix is often associated with a `Good` Credit_Score.â€"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.4 Categorical variable - Payment_of_Min_Amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is all the Category Columns We have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:02:13.932906Z",
     "iopub.status.busy": "2025-08-16T10:02:13.932195Z",
     "iopub.status.idle": "2025-08-16T10:02:13.938091Z",
     "shell.execute_reply": "2025-08-16T10:02:13.937216Z",
     "shell.execute_reply.started": "2025-08-16T10:02:13.932876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# find categorical Columns and put that into a \n",
    "# Find all columns with 'category' dtype\n",
    "cat_cols = [var for var in credit_df.columns if credit_df[var].dtype.name == 'category']\n",
    "\n",
    "print('There are {} category variables\\n'.format(len(cat_cols)))\n",
    "print('The category variables are:\\n\\n', cat_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:02:16.041516Z",
     "iopub.status.busy": "2025-08-16T10:02:16.040705Z",
     "iopub.status.idle": "2025-08-16T10:02:16.049779Z",
     "shell.execute_reply": "2025-08-16T10:02:16.048996Z",
     "shell.execute_reply.started": "2025-08-16T10:02:16.041422Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Value counts of the column - Payment_of_Min_Amount\n",
    "\n",
    "min_amount_count = credit_df['Payment_of_Min_Amount'].value_counts(dropna = False)\n",
    "min_amount_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:02:28.556382Z",
     "iopub.status.busy": "2025-08-16T10:02:28.556081Z",
     "iopub.status.idle": "2025-08-16T10:02:28.732826Z",
     "shell.execute_reply": "2025-08-16T10:02:28.731962Z",
     "shell.execute_reply.started": "2025-08-16T10:02:28.556358Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Bar graph showing the value counts of the column - Payment_of_Min_Amount\n",
    "\n",
    "sns.set(rc = {'figure.figsize': (5, 5)})\n",
    "sns.barplot(x=min_amount_count.index, y=min_amount_count.values, alpha = 0.8)\n",
    "plt.title('Bar graph showing the value counts of the column - Payment_of_Min_Amount')\n",
    "plt.ylabel('Number of Occurrences', fontsize = 12)\n",
    "plt.xlabel('Payment of Minimum Amount', fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, we can see that most of the customer's paid a minimum amount for their loans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:02:37.040664Z",
     "iopub.status.busy": "2025-08-16T10:02:37.040148Z",
     "iopub.status.idle": "2025-08-16T10:02:37.847095Z",
     "shell.execute_reply": "2025-08-16T10:02:37.846354Z",
     "shell.execute_reply.started": "2025-08-16T10:02:37.040637Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Distribution of Payment_of_Min_Amount for each Credit Score\n",
    "\n",
    "sns.catplot(\n",
    "    x='Payment_of_Min_Amount', \n",
    "    col='Credit_Score', \n",
    "    data=credit_df, \n",
    "    kind='count', \n",
    "    col_wrap=3,\n",
    "    height=4,\n",
    "    aspect=1\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "When `Payment_of_Min_Amount` is \"No\" â†’ `Credit_Score` is mostly \"Good\".\n",
    "\n",
    "Suggests that people who donâ€™t just pay the minimum amount might be financially stronger, thus having better credit scores.\n",
    "\n",
    "When `Credit_Score` is \"Poor\" â†’ `Payment_of_Min_Amount` is mostly \"Yes\".\n",
    "\n",
    "Indicates that struggling borrowers are more likely to pay only the minimum required, which could hurt their credit score.\n",
    "\n",
    "When `Credit_Score` is \"Standard\" â†’ `Payment_of_Min_Amount` is also mostly \"Yes\".\n",
    "\n",
    "Shows that paying only the minimum doesnâ€™t necessarily mean \"Poor\" score, but it tends to keep people in a middle (\"Standard\") range instead of \"Good\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph we can Observe:\n",
    "Paying only the minimum amount is generally associated with lower or average credit scores.\n",
    "\n",
    "Not paying the minimum amount (i.e., paying more) is correlated with a Good credit score.\n",
    "\n",
    "This could indicate that payment habits are an important predictor for creditworthiness â€” people paying more than the minimum may have better financial discipline or income, leading to stronger credit profiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:02:42.770635Z",
     "iopub.status.busy": "2025-08-16T10:02:42.770003Z",
     "iopub.status.idle": "2025-08-16T10:02:42.776413Z",
     "shell.execute_reply": "2025-08-16T10:02:42.775712Z",
     "shell.execute_reply.started": "2025-08-16T10:02:42.770607Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df['Payment_of_Min_Amount'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.5 Numerical variable - Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:02:50.352400Z",
     "iopub.status.busy": "2025-08-16T10:02:50.351790Z",
     "iopub.status.idle": "2025-08-16T10:02:51.252151Z",
     "shell.execute_reply": "2025-08-16T10:02:51.251215Z",
     "shell.execute_reply.started": "2025-08-16T10:02:50.352378Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Understanding the distribution of the column - Age\n",
    "# This is for old Version because now distplot become displot\n",
    "sns.distplot(credit_df['Age'], label = 'Skewness: %.2f'%(credit_df['Age'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Customer Age Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:02:51.449212Z",
     "iopub.status.busy": "2025-08-16T10:02:51.448740Z",
     "iopub.status.idle": "2025-08-16T10:02:52.340407Z",
     "shell.execute_reply": "2025-08-16T10:02:52.339606Z",
     "shell.execute_reply.started": "2025-08-16T10:02:51.449178Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This is for new Version\n",
    "sns.displot(credit_df['Age'],kind=\"kde\", label = 'Skewness: %.2f'%(credit_df['Age'].skew()))\n",
    "plt.legend(loc='best')\n",
    "plt.title('Customer Age Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:02:54.865296Z",
     "iopub.status.busy": "2025-08-16T10:02:54.865010Z",
     "iopub.status.idle": "2025-08-16T10:02:54.874713Z",
     "shell.execute_reply": "2025-08-16T10:02:54.873912Z",
     "shell.execute_reply.started": "2025-08-16T10:02:54.865274Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:02:57.411416Z",
     "iopub.status.busy": "2025-08-16T10:02:57.411137Z",
     "iopub.status.idle": "2025-08-16T10:02:57.417476Z",
     "shell.execute_reply": "2025-08-16T10:02:57.416851Z",
     "shell.execute_reply.started": "2025-08-16T10:02:57.411395Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df['Age'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, we can see that the above graph has a high degree of skewness.\n",
    "A skewness of 9.21 is extremely high, which means your data is very heavily positively skewed (right-skewed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.6 Numerical variable - Monthly_Inhand_Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:03:01.172121Z",
     "iopub.status.busy": "2025-08-16T10:03:01.171572Z",
     "iopub.status.idle": "2025-08-16T10:03:01.973138Z",
     "shell.execute_reply": "2025-08-16T10:03:01.972343Z",
     "shell.execute_reply.started": "2025-08-16T10:03:01.172096Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Understanding the distribution of the column - Monthly_Inhand_Salary\n",
    "\n",
    "sns.distplot(credit_df['Monthly_Inhand_Salary'], label = 'Skewness: %.2f'%(credit_df['Monthly_Inhand_Salary'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Customer Monthly Salary Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:03:04.834418Z",
     "iopub.status.busy": "2025-08-16T10:03:04.833887Z",
     "iopub.status.idle": "2025-08-16T10:03:05.800356Z",
     "shell.execute_reply": "2025-08-16T10:03:05.799492Z",
     "shell.execute_reply.started": "2025-08-16T10:03:04.834396Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sns.displot(\n",
    "    credit_df['Monthly_Inhand_Salary'], \n",
    "    kde=True, \n",
    "    stat=\"density\",  # Show density instead of counts\n",
    "    label='Skewness: %.2f' % (credit_df['Monthly_Inhand_Salary'].skew())\n",
    ")\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.title('Customer Monthly Salary Distribution')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, we can see that the distribution is right skewed and has a slight degree of skewness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:03:08.846942Z",
     "iopub.status.busy": "2025-08-16T10:03:08.846648Z",
     "iopub.status.idle": "2025-08-16T10:03:10.630780Z",
     "shell.execute_reply": "2025-08-16T10:03:10.629846Z",
     "shell.execute_reply.started": "2025-08-16T10:03:08.846918Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Monthly Inhand Salary distribution by Credit Score\n",
    "\n",
    "grid = sns.FacetGrid(credit_df, col = 'Credit_Score')\n",
    "grid.map(sns.distplot, 'Monthly_Inhand_Salary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:03:10.660725Z",
     "iopub.status.busy": "2025-08-16T10:03:10.660370Z",
     "iopub.status.idle": "2025-08-16T10:03:11.466842Z",
     "shell.execute_reply": "2025-08-16T10:03:11.466037Z",
     "shell.execute_reply.started": "2025-08-16T10:03:10.660700Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Merging the above graphs into one\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "for score in ['Good', 'Poor', 'Standard']:\n",
    "    sns.kdeplot(\n",
    "        data=credit_df[credit_df['Credit_Score'] == score]['Monthly_Inhand_Salary'],\n",
    "        label=f'Credit Score = {score}'\n",
    "    )\n",
    "\n",
    "plt.xlabel('Monthly Inhand Salary')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Customer Monthly Inhand Salary by Credit Score')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, we can see that most of the customer's who have a Poor credit score have a low monthly inhand salary than compared to the customer's who have a Standard and a Good credit score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.7 Numerical variable - Interest_Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:03:15.332019Z",
     "iopub.status.busy": "2025-08-16T10:03:15.331225Z",
     "iopub.status.idle": "2025-08-16T10:03:16.191197Z",
     "shell.execute_reply": "2025-08-16T10:03:16.190399Z",
     "shell.execute_reply.started": "2025-08-16T10:03:15.331993Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Understanding the distribution of the column - Interest_Rate\n",
    "\n",
    "sns.distplot(credit_df['Interest_Rate'], label = 'Skewness: %.2f'%(credit_df['Interest_Rate'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Customers Interest Rate Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, we can see that the above graph has a high degree of skewness.\n",
    "So,\n",
    "datasetâ€™s skewness = 9.01, thatâ€™s extremely high â€” meaning our data is very heavily right-skewed (positively skewed).\n",
    "\n",
    "Hereâ€™s what it implies:\n",
    "\n",
    "Shape â†’ The distribution has a long tail on the right side.\n",
    "\n",
    "Mean > Median â†’ The mean will be much larger than the median.\n",
    "\n",
    "Outliers â†’ You likely have extreme high-value outliers pulling the tail to the right.\n",
    "\n",
    "Normality â†’ The data is far from normal; statistical models that assume normality (e.g., many parametric tests) may perform poorly unless transformed.\n",
    "\n",
    "Handling â†’ Often, such data benefits from transformations like log, square root, or Box-Cox to reduce skewness before modeling.\n",
    "\n",
    "ðŸ“Œ `Rule of thumb for skewness:`\n",
    "\n",
    "`0` â†’ perfectly symmetric\n",
    "\n",
    "`0 to Â±0.5` â†’ fairly symmetric\n",
    "\n",
    "`Â±0.5 to Â±1` â†’ moderately skewed\n",
    "\n",
    "`Â±1` â†’ highly skewed\n",
    "\n",
    "`9.01` â†’ extremely skewed ðŸš¨(It's Our)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2.8 Numerical variable - Outstanding_Debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:03:18.436944Z",
     "iopub.status.busy": "2025-08-16T10:03:18.436169Z",
     "iopub.status.idle": "2025-08-16T10:03:19.218549Z",
     "shell.execute_reply": "2025-08-16T10:03:19.217778Z",
     "shell.execute_reply.started": "2025-08-16T10:03:18.436919Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Understanding the distribution of the column - Outstanding_Debt\n",
    "\n",
    "sns.distplot(credit_df['Outstanding_Debt'], label = 'Skewness: %.2f'%(credit_df['Outstanding_Debt'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title(\"Customer's Outstanding Debt  Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:03:24.036201Z",
     "iopub.status.busy": "2025-08-16T10:03:24.035681Z",
     "iopub.status.idle": "2025-08-16T10:03:24.063868Z",
     "shell.execute_reply": "2025-08-16T10:03:24.063149Z",
     "shell.execute_reply.started": "2025-08-16T10:03:24.036178Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_scores = ['Good', 'Poor', 'Standard']\n",
    "\n",
    "for score in credit_scores:\n",
    "    count = credit_df[\n",
    "        (credit_df['Credit_Score'] == score) &\n",
    "        (credit_df['Outstanding_Debt'].notnull())\n",
    "    ].shape[0]\n",
    "    print(f\"Credit Score = {score} â†’ Count = {count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:03:25.791765Z",
     "iopub.status.busy": "2025-08-16T10:03:25.791171Z",
     "iopub.status.idle": "2025-08-16T10:03:27.443168Z",
     "shell.execute_reply": "2025-08-16T10:03:27.442316Z",
     "shell.execute_reply.started": "2025-08-16T10:03:25.791738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Outstanding Debt distribution by Credit Score\n",
    "\n",
    "grid = sns.FacetGrid(credit_df, col = 'Credit_Score')\n",
    "grid.map(sns.distplot, 'Outstanding_Debt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:03:27.615862Z",
     "iopub.status.busy": "2025-08-16T10:03:27.615260Z",
     "iopub.status.idle": "2025-08-16T10:03:28.434399Z",
     "shell.execute_reply": "2025-08-16T10:03:28.433619Z",
     "shell.execute_reply.started": "2025-08-16T10:03:27.615839Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "for score in ['Good', 'Poor', 'Standard']:\n",
    "    data = credit_df.loc[credit_df['Credit_Score'] == score, 'Outstanding_Debt']\n",
    "    sns.kdeplot(data, label=f'Credit Score = {score}')\n",
    "\n",
    "plt.xlabel(\"Customer's Outstanding Debt\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Customer's Outstanding Debt by Credit Score\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, we can see that customer's who have a Good credit score have very low outstanding debt than compared to the customer's who have Standard and Poor credit score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing is the process of getting our dataset ready for model training. In this section, we will perform the following preprocessing steps:\n",
    "\n",
    "1. Detect and remove outliers in numerical variables\n",
    "2. Drop and fill missing values\n",
    "3. Feature engineering\n",
    "4. Data trasformation\n",
    "5. Feature encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 Detect and remove outliers in numerical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers are data points that have extreme values and they do not conform with the majority of the data. It is important to address this because outliers tend to skew our data towards extremes and can cause inaccurate model predictions. I will use the Tukey method to remove these outliers.\n",
    "\n",
    "Here, we will write a function that will loop through a list of features and detect outliers in each one of those features. In each loop, a data point is deemed an outlier if it is less than the first quartile minus the outlier step or exceeds third quartile plus the outlier step. The outlier step is defined as 1.5 times the interquartile range. Once the outliers have been determined for one feature, their indices will be stored in a list before proceeding to the next feature and the process repeats until the very last feature is completed. Finally, using the list with outlier indices, we will count the frequencies of the index numbers and return them if their frequency exceeds n times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:03:36.201220Z",
     "iopub.status.busy": "2025-08-16T10:03:36.200444Z",
     "iopub.status.idle": "2025-08-16T10:03:36.204558Z",
     "shell.execute_reply": "2025-08-16T10:03:36.203869Z",
     "shell.execute_reply.started": "2025-08-16T10:03:36.201196Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:03:41.325566Z",
     "iopub.status.busy": "2025-08-16T10:03:41.325250Z",
     "iopub.status.idle": "2025-08-16T10:03:41.331397Z",
     "shell.execute_reply": "2025-08-16T10:03:41.330510Z",
     "shell.execute_reply.started": "2025-08-16T10:03:41.325545Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def detect_outliers(df, n, features_list):\n",
    "    outlier_indices = [] \n",
    "    for feature in features_list: \n",
    "        Q1 = np.percentile(df[feature], 25)\n",
    "        Q3 = np.percentile(df[feature], 75)\n",
    "        IQR = Q3 - Q1\n",
    "        outlier_step = 1.5 * IQR \n",
    "        outlier_list_col = df[(df[feature] < Q1 - outlier_step) | (df[feature] > Q3 + outlier_step)].index\n",
    "        outlier_indices.extend(outlier_list_col) \n",
    "    outlier_indices = Counter(outlier_indices)\n",
    "    multiple_outliers = list(key for key, value in outlier_indices.items() if value > n) \n",
    "    return multiple_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:03:44.297873Z",
     "iopub.status.busy": "2025-08-16T10:03:44.297577Z",
     "iopub.status.idle": "2025-08-16T10:03:44.400353Z",
     "shell.execute_reply": "2025-08-16T10:03:44.399538Z",
     "shell.execute_reply.started": "2025-08-16T10:03:44.297851Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "numerical_columns = list(credit_df.select_dtypes('number').columns)\n",
    "print('Numerical columns: {}'.format(numerical_columns))\n",
    "outliers_to_drop = detect_outliers(credit_df, 2, numerical_columns)\n",
    "print(\"We will drop these {} indices: \".format(len(outliers_to_drop)), outliers_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the data present in the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:03:50.775563Z",
     "iopub.status.busy": "2025-08-16T10:03:50.774966Z",
     "iopub.status.idle": "2025-08-16T10:03:50.804814Z",
     "shell.execute_reply": "2025-08-16T10:03:50.804052Z",
     "shell.execute_reply.started": "2025-08-16T10:03:50.775528Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df.iloc[outliers_to_drop, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above all the thing is outlier so we are going to drop it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will drop these rows from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:09:53.318442Z",
     "iopub.status.busy": "2025-08-16T10:09:53.317445Z",
     "iopub.status.idle": "2025-08-16T10:09:53.359176Z",
     "shell.execute_reply": "2025-08-16T10:09:53.358416Z",
     "shell.execute_reply.started": "2025-08-16T10:09:53.318412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Drop outliers and reset index\n",
    "\n",
    "print(\"Before: {} rows\".format(len(credit_df)))\n",
    "credit_df = credit_df.drop(outliers_to_drop, axis = 0).reset_index(drop = True)\n",
    "print(\"After: {} rows\".format(len(credit_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:10:01.917025Z",
     "iopub.status.busy": "2025-08-16T10:10:01.916375Z",
     "iopub.status.idle": "2025-08-16T10:10:01.944093Z",
     "shell.execute_reply": "2025-08-16T10:10:01.943328Z",
     "shell.execute_reply.started": "2025-08-16T10:10:01.917000Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Lets look at the new dataset\n",
    "\n",
    "credit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Drop and fill missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will drop the columns - ID, Customer_ID, Name, SSN, Credit_Mix, Num_of_Loan, Credit_Utilization_Ratio, Credit_History_Age, Payment_Behavior, Annual_Income, Monthly_Balance, Num_Bank_Accounts, Num_Credit_Card from the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:11:00.363116Z",
     "iopub.status.busy": "2025-08-16T10:11:00.362817Z",
     "iopub.status.idle": "2025-08-16T10:11:00.388432Z",
     "shell.execute_reply": "2025-08-16T10:11:00.387701Z",
     "shell.execute_reply.started": "2025-08-16T10:11:00.363092Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Dropping the columns from the dataset\n",
    "\n",
    "credit_df.drop(['ID', 'Customer_ID', 'Name', 'SSN', 'Credit_Mix', 'Num_of_Loan',\n",
    "             'Credit_Utilization_Ratio', 'Credit_History_Age', 'Payment_Behaviour', \n",
    "             'Annual_Income', 'Monthly_Balance', 'Num_Bank_Accounts', 'Num_Credit_Card'], axis = 1, inplace = True)\n",
    "credit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:11:27.114139Z",
     "iopub.status.busy": "2025-08-16T10:11:27.113393Z",
     "iopub.status.idle": "2025-08-16T10:11:27.128495Z",
     "shell.execute_reply": "2025-08-16T10:11:27.127645Z",
     "shell.execute_reply.started": "2025-08-16T10:11:27.114110Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:14:38.321069Z",
     "iopub.status.busy": "2025-08-16T10:14:38.320769Z",
     "iopub.status.idle": "2025-08-16T10:14:38.332837Z",
     "shell.execute_reply": "2025-08-16T10:14:38.332116Z",
     "shell.execute_reply.started": "2025-08-16T10:14:38.321046Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Looking at the missing values in the dataset\n",
    "\n",
    "credit_df.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above data, we can see that there are missing values in the columns - `Monthly_Inhand_Salary`, `Type_of_Loan`, `Num_of_Delayed_Payment`, `Amount_invested_monthly`, `Num_Credit_Inquiries`. Here, we will focus on removing the missing values in the columns - `Monthly_Inhand_Salary`, `Num_of_Delayed_Payment`, `Amount_invested_monthly`, and `Num_Credit_Inquiries`. However, we will replace the missing values in the column - Type_of_Loan in the Feature Engineering section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2.1 Handling missing values - Monthly_Inhand_Salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, for replacing the missing values in the column - Monthly_Inhand_Salary, we will use the column Credit_Score and find the mean of the salary based on the Credit Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:15:03.814031Z",
     "iopub.status.busy": "2025-08-16T10:15:03.813720Z",
     "iopub.status.idle": "2025-08-16T10:15:03.824296Z",
     "shell.execute_reply": "2025-08-16T10:15:03.823583Z",
     "shell.execute_reply.started": "2025-08-16T10:15:03.814006Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Finding mean Monthly_Inhand_Salary for each Credit_Score category\n",
    "salary_means = credit_df.groupby('Credit_Score')['Monthly_Inhand_Salary'].mean()\n",
    "\n",
    "salary_good_mean = salary_means.get('Good')\n",
    "salary_poor_mean = salary_means.get('Poor')\n",
    "salary_standard_mean = salary_means.get('Standard')\n",
    "\n",
    "(salary_good_mean, salary_poor_mean, salary_standard_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:15:12.609630Z",
     "iopub.status.busy": "2025-08-16T10:15:12.608993Z",
     "iopub.status.idle": "2025-08-16T10:15:12.629536Z",
     "shell.execute_reply": "2025-08-16T10:15:12.628786Z",
     "shell.execute_reply.started": "2025-08-16T10:15:12.609604Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Finding the indices of the rows where Monthly_Inhand_Salary is null\n",
    "\n",
    "index_values = list(credit_df['Monthly_Inhand_Salary'].isnull())\n",
    "index_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:15:34.393981Z",
     "iopub.status.busy": "2025-08-16T10:15:34.393293Z",
     "iopub.status.idle": "2025-08-16T10:15:36.318442Z",
     "shell.execute_reply": "2025-08-16T10:15:36.317560Z",
     "shell.execute_reply.started": "2025-08-16T10:15:34.393955Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Replacing the missing values in the column Monthly_Inhand_Salary using the decision logic\n",
    "\n",
    "for index in range(len(credit_df)):\n",
    "    if index_values[index]:\n",
    "        if credit_df['Credit_Score'][index] == 'Good':\n",
    "            credit_df['Monthly_Inhand_Salary'][index] = salary_good_mean\n",
    "        elif credit_df['Credit_Score'][index] == 'Poor':\n",
    "            credit_df['Monthly_Inhand_Salary'][index] = salary_poor_mean\n",
    "        else:\n",
    "            credit_df['Monthly_Inhand_Salary'][index] = salary_standard_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:15:37.908276Z",
     "iopub.status.busy": "2025-08-16T10:15:37.907980Z",
     "iopub.status.idle": "2025-08-16T10:15:37.914780Z",
     "shell.execute_reply": "2025-08-16T10:15:37.913958Z",
     "shell.execute_reply.started": "2025-08-16T10:15:37.908252Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Checking if there are any missing values of Monthly_Inhand_Salary in the dataset\n",
    "\n",
    "credit_df['Monthly_Inhand_Salary'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replaced all the missing values present in the column - `Monthly_Inhand_Salary`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2.2 Handling missing values - Num_of_Delayed_Payment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will use the median to replace the missing values in the column - `Num_of_Delayed_Payment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:15:42.253384Z",
     "iopub.status.busy": "2025-08-16T10:15:42.253090Z",
     "iopub.status.idle": "2025-08-16T10:15:42.259942Z",
     "shell.execute_reply": "2025-08-16T10:15:42.259084Z",
     "shell.execute_reply.started": "2025-08-16T10:15:42.253361Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df['Num_of_Delayed_Payment'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:15:46.284731Z",
     "iopub.status.busy": "2025-08-16T10:15:46.284063Z",
     "iopub.status.idle": "2025-08-16T10:15:46.290938Z",
     "shell.execute_reply": "2025-08-16T10:15:46.290228Z",
     "shell.execute_reply.started": "2025-08-16T10:15:46.284706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Finding the median value of the column - Num_of_Delayed_Payment in the dataset\n",
    "\n",
    "#payment_index = list(~train_df['Num_of_Delayed_Payment'].isnull())\n",
    "#median_payment = np.median(train_df['Num_of_Delayed_Payment'].loc[payment_index])\n",
    "median_payment = credit_df['Num_of_Delayed_Payment'].median()  #Pandasâ€™ built-in .median() already ignores NaNs by default\n",
    "\n",
    "median_payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:15:50.451598Z",
     "iopub.status.busy": "2025-08-16T10:15:50.451266Z",
     "iopub.status.idle": "2025-08-16T10:15:50.456863Z",
     "shell.execute_reply": "2025-08-16T10:15:50.456155Z",
     "shell.execute_reply.started": "2025-08-16T10:15:50.451572Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Replacing the missing values of the column - Num_of_Delayed_Payment in the dataset\n",
    "\n",
    "credit_df['Num_of_Delayed_Payment'].fillna(median_payment, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:15:52.845453Z",
     "iopub.status.busy": "2025-08-16T10:15:52.845190Z",
     "iopub.status.idle": "2025-08-16T10:15:52.851946Z",
     "shell.execute_reply": "2025-08-16T10:15:52.851055Z",
     "shell.execute_reply.started": "2025-08-16T10:15:52.845433Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df['Num_of_Delayed_Payment'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replaced all the missing values present in the column - `Num_of_Delayed_Payment`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2.3 Handling missing values - `Amount_invested_monthly`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:16:00.285336Z",
     "iopub.status.busy": "2025-08-16T10:16:00.285051Z",
     "iopub.status.idle": "2025-08-16T10:16:00.292136Z",
     "shell.execute_reply": "2025-08-16T10:16:00.291120Z",
     "shell.execute_reply.started": "2025-08-16T10:16:00.285313Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df['Amount_invested_monthly'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will use the median to replace the missing values in the column - Amount_invested_monthly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:16:06.211957Z",
     "iopub.status.busy": "2025-08-16T10:16:06.211316Z",
     "iopub.status.idle": "2025-08-16T10:16:06.218253Z",
     "shell.execute_reply": "2025-08-16T10:16:06.217558Z",
     "shell.execute_reply.started": "2025-08-16T10:16:06.211930Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Finding the median value of the column - Amount_invested_monthly in the dataset\n",
    "\n",
    "median_amount = credit_df['Amount_invested_monthly'].median()\n",
    "median_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:16:08.619620Z",
     "iopub.status.busy": "2025-08-16T10:16:08.619289Z",
     "iopub.status.idle": "2025-08-16T10:16:08.624920Z",
     "shell.execute_reply": "2025-08-16T10:16:08.624107Z",
     "shell.execute_reply.started": "2025-08-16T10:16:08.619597Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Replacing the missing values of the column - Amount_invested_monthly in the dataset\n",
    "\n",
    "credit_df['Amount_invested_monthly'].fillna(median_amount, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:16:10.294828Z",
     "iopub.status.busy": "2025-08-16T10:16:10.294526Z",
     "iopub.status.idle": "2025-08-16T10:16:10.302016Z",
     "shell.execute_reply": "2025-08-16T10:16:10.301045Z",
     "shell.execute_reply.started": "2025-08-16T10:16:10.294805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df['Amount_invested_monthly'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replaced all the missing values present in the column - Amount_invested_monthly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2.4 Handling missing values - Num_Credit_Inquiries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will use the median to replace the missing values in the column - `Num_Credit_Inquiries`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:16:16.453428Z",
     "iopub.status.busy": "2025-08-16T10:16:16.453146Z",
     "iopub.status.idle": "2025-08-16T10:16:16.459425Z",
     "shell.execute_reply": "2025-08-16T10:16:16.458678Z",
     "shell.execute_reply.started": "2025-08-16T10:16:16.453406Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Finding the median value of the column - Num_Credit_Inquiries in the dataset\n",
    "median_inquiries = credit_df['Num_Credit_Inquiries'].median()\n",
    "median_inquiries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:16:18.226421Z",
     "iopub.status.busy": "2025-08-16T10:16:18.225663Z",
     "iopub.status.idle": "2025-08-16T10:16:18.231590Z",
     "shell.execute_reply": "2025-08-16T10:16:18.230795Z",
     "shell.execute_reply.started": "2025-08-16T10:16:18.226396Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Replacing the missing values of the column - Num_Credit_Inquiries in the dataset\n",
    "\n",
    "credit_df['Num_Credit_Inquiries'].fillna(median_inquiries, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:16:19.915426Z",
     "iopub.status.busy": "2025-08-16T10:16:19.915163Z",
     "iopub.status.idle": "2025-08-16T10:16:19.921474Z",
     "shell.execute_reply": "2025-08-16T10:16:19.920824Z",
     "shell.execute_reply.started": "2025-08-16T10:16:19.915406Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Checking if there are any missing values of Num_Credit_Inquiries in the dataset\n",
    "credit_df['Num_Credit_Inquiries'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We replaced all the missing values present in the column - `Num_Credit_Inquiries`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T12:37:23.578774Z",
     "iopub.status.busy": "2025-08-15T12:37:23.578481Z",
     "iopub.status.idle": "2025-08-15T12:37:23.590647Z",
     "shell.execute_reply": "2025-08-15T12:37:23.589659Z",
     "shell.execute_reply.started": "2025-08-15T12:37:23.578754Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Looking if the dataset has any more missing values apart from Type_of_Loan\n",
    "\n",
    "credit_df.isnull().sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:16:43.519327Z",
     "iopub.status.busy": "2025-08-16T10:16:43.519056Z",
     "iopub.status.idle": "2025-08-16T10:16:43.533611Z",
     "shell.execute_reply": "2025-08-16T10:16:43.532876Z",
     "shell.execute_reply.started": "2025-08-16T10:16:43.519307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, there are no missing values in the data apart from the data in the column - `Type_of_Loan` (which we will deal in the `Feature Engineering`), we can proceed to perform Feature Engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering is arguably the most important art in machine learning. It is the process of creating new features from existing features to better represent the underlying problem to the predictive models resulting in improved model accuracy on unseen data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we focus on creating new columns for:\n",
    "\n",
    "1.Individual columns for `Type_of_Loan`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3.1 Individual columns for `Type_of_Loan`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will create 8 different columns using the loan_type_dict dictionary. Here, we will not consider the value Not Specified for the loan type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:18:42.485151Z",
     "iopub.status.busy": "2025-08-16T10:18:42.484615Z",
     "iopub.status.idle": "2025-08-16T10:18:42.490326Z",
     "shell.execute_reply": "2025-08-16T10:18:42.489525Z",
     "shell.execute_reply.started": "2025-08-16T10:18:42.485129Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Looking at the loan_type_dict\n",
    "\n",
    "loan_type_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:18:47.855149Z",
     "iopub.status.busy": "2025-08-16T10:18:47.854594Z",
     "iopub.status.idle": "2025-08-16T10:18:48.021434Z",
     "shell.execute_reply": "2025-08-16T10:18:48.020729Z",
     "shell.execute_reply.started": "2025-08-16T10:18:47.855125Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This is for how many unique types of loan we have\n",
    "unique_loans = set()  # to store unique loan types\n",
    "\n",
    "for entry in loan_type_data:\n",
    "    # Replace ' and ' with ', ' so we can split everything by comma\n",
    "    clean_entry = entry.replace(' and ', ', ')\n",
    "    \n",
    "    # Split by comma\n",
    "    for loan in clean_entry.split(','):\n",
    "        loan = loan.strip()  # remove extra spaces\n",
    "        if loan and loan != \"Not Specified\":  # skip empty & unwanted\n",
    "            unique_loans.add(loan)\n",
    "\n",
    "print(unique_loans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:19:14.811004Z",
     "iopub.status.busy": "2025-08-16T10:19:14.810357Z",
     "iopub.status.idle": "2025-08-16T10:19:14.816539Z",
     "shell.execute_reply": "2025-08-16T10:19:14.815612Z",
     "shell.execute_reply.started": "2025-08-16T10:19:14.810979Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Creating 8 different lists for each loan type\n",
    "# Here basically we are createing a list with the same length of the dataset and then felling all the values with the zero.\n",
    "auto_loan = [0] * (len(credit_df))\n",
    "credit_builder_loan = [0] * (len(credit_df))\n",
    "personal_loan = [0] * (len(credit_df))\n",
    "home_equity_loan = [0] * (len(credit_df))\n",
    "mortgage_loan = [0] * (len(credit_df))\n",
    "student_loan = [0] * (len(credit_df))\n",
    "debt_consolidation_loan = [0] * (len(credit_df))\n",
    "payday_loan = [0] * (len(credit_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:19:30.716860Z",
     "iopub.status.busy": "2025-08-16T10:19:30.716217Z",
     "iopub.status.idle": "2025-08-16T10:19:30.738674Z",
     "shell.execute_reply": "2025-08-16T10:19:30.737996Z",
     "shell.execute_reply.started": "2025-08-16T10:19:30.716835Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pd.Series(loan_type_data).nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:19:35.494894Z",
     "iopub.status.busy": "2025-08-16T10:19:35.494608Z",
     "iopub.status.idle": "2025-08-16T10:19:35.500095Z",
     "shell.execute_reply": "2025-08-16T10:19:35.499426Z",
     "shell.execute_reply.started": "2025-08-16T10:19:35.494875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "len(loan_type_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:19:38.342373Z",
     "iopub.status.busy": "2025-08-16T10:19:38.341782Z",
     "iopub.status.idle": "2025-08-16T10:19:38.431697Z",
     "shell.execute_reply": "2025-08-16T10:19:38.430959Z",
     "shell.execute_reply.started": "2025-08-16T10:19:38.342349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for index in range(len(loan_type_data)):\n",
    "    ### For Auto Loan\n",
    "    if 'Auto' in loan_type_data[index]:\n",
    "        auto_loan[index] = 1\n",
    "    \n",
    "    ### For Credit Builder Loan\n",
    "    if 'Credit-Builder' in loan_type_data[index]:\n",
    "        credit_builder_loan[index] = 1\n",
    "        \n",
    "    ### For Personal Loan\n",
    "    if 'Personal' in loan_type_data[index]:\n",
    "        personal_loan[index] = 1\n",
    "    \n",
    "    ### For Home Equity Loan\n",
    "    if 'Home' in loan_type_data[index]:\n",
    "        home_equity_loan[index] = 1\n",
    "    \n",
    "    ### For Mortgage Loan\n",
    "    if 'Mortgage' in loan_type_data[index]:\n",
    "        mortgage_loan[index] = 1\n",
    "    \n",
    "    ### For Student Loan\n",
    "    if 'Student' in loan_type_data[index]:\n",
    "        student_loan[index] = 1\n",
    "        \n",
    "    ### For Debt Consolidation loan\n",
    "    if 'Debt' in loan_type_data[index]:\n",
    "        debt_consolidation_loan[index] = 1\n",
    "    \n",
    "    ### For Payday loan\n",
    "    if 'Payday' in loan_type_data[index]:\n",
    "        payday_loan[index] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:19:41.911649Z",
     "iopub.status.busy": "2025-08-16T10:19:41.910902Z",
     "iopub.status.idle": "2025-08-16T10:19:42.106317Z",
     "shell.execute_reply": "2025-08-16T10:19:42.105373Z",
     "shell.execute_reply.started": "2025-08-16T10:19:41.911620Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Adding the new columns to the dataset\n",
    "\n",
    "credit_df['Auto_Loan'] = auto_loan\n",
    "credit_df['Credit_Builder_Loan'] = credit_builder_loan\n",
    "credit_df['Personal_Loan'] = personal_loan\n",
    "credit_df['Home_Enquity_Loan'] = home_equity_loan\n",
    "credit_df['Mortgage_Loan'] = mortgage_loan\n",
    "credit_df['Student_Loan'] = student_loan\n",
    "credit_df['Debt_Consolidation_Loan'] = debt_consolidation_loan\n",
    "credit_df['Payday_Loan'] = payday_loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:19:44.187476Z",
     "iopub.status.busy": "2025-08-16T10:19:44.186454Z",
     "iopub.status.idle": "2025-08-16T10:19:44.197104Z",
     "shell.execute_reply": "2025-08-16T10:19:44.196307Z",
     "shell.execute_reply.started": "2025-08-16T10:19:44.187427Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Removing the column - Type_of_loan\n",
    "\n",
    "credit_df.drop(['Type_of_Loan'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:19:44.944214Z",
     "iopub.status.busy": "2025-08-16T10:19:44.943945Z",
     "iopub.status.idle": "2025-08-16T10:19:44.956267Z",
     "shell.execute_reply": "2025-08-16T10:19:44.955456Z",
     "shell.execute_reply.started": "2025-08-16T10:19:44.944195Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can see that we don't have any types of null values now "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:19:55.468045Z",
     "iopub.status.busy": "2025-08-16T10:19:55.467780Z",
     "iopub.status.idle": "2025-08-16T10:19:55.490813Z",
     "shell.execute_reply": "2025-08-16T10:19:55.489724Z",
     "shell.execute_reply.started": "2025-08-16T10:19:55.468026Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Now this is how our dataset looks like\n",
    "credit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:20:08.906965Z",
     "iopub.status.busy": "2025-08-16T10:20:08.906692Z",
     "iopub.status.idle": "2025-08-16T10:20:08.922164Z",
     "shell.execute_reply": "2025-08-16T10:20:08.921316Z",
     "shell.execute_reply.started": "2025-08-16T10:20:08.906945Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:21:08.061857Z",
     "iopub.status.busy": "2025-08-16T10:21:08.061555Z",
     "iopub.status.idle": "2025-08-16T10:21:08.089273Z",
     "shell.execute_reply": "2025-08-16T10:21:08.088396Z",
     "shell.execute_reply.started": "2025-08-16T10:21:08.061832Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set the display option to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Now, filter and display your DataFrame\n",
    "good_credit_df = credit_df[credit_df['Credit_Score'] == 'Good']\n",
    "\n",
    "# This will now print all the columns without skipping any\n",
    "good_credit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:23:29.365285Z",
     "iopub.status.busy": "2025-08-16T10:23:29.364713Z",
     "iopub.status.idle": "2025-08-16T10:23:29.392362Z",
     "shell.execute_reply": "2025-08-16T10:23:29.391621Z",
     "shell.execute_reply.started": "2025-08-16T10:23:29.365261Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set the display option to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Now, filter and display your DataFrame\n",
    "Poor_credit_df = credit_df[credit_df['Credit_Score'] == 'Poor']\n",
    "\n",
    "# This will now print all the columns without skipping any\n",
    "Poor_credit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:24:02.230166Z",
     "iopub.status.busy": "2025-08-16T10:24:02.229298Z",
     "iopub.status.idle": "2025-08-16T10:24:02.258224Z",
     "shell.execute_reply": "2025-08-16T10:24:02.257422Z",
     "shell.execute_reply.started": "2025-08-16T10:24:02.230138Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set the display option to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Now, filter and display your DataFrame\n",
    "Standard_credit_df = credit_df[credit_df['Credit_Score'] == 'Standard']\n",
    "\n",
    "# This will now print all the columns without skipping any\n",
    "Standard_credit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the dataset, we can see that there is a lot of skewness in the numerical columns of the dataset. Here, we will focus on removing the skewness in the data using `log transformation`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4.1 Log Transforming the column - `Age`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:24:36.280757Z",
     "iopub.status.busy": "2025-08-16T10:24:36.279693Z",
     "iopub.status.idle": "2025-08-16T10:24:36.287657Z",
     "shell.execute_reply": "2025-08-16T10:24:36.286606Z",
     "shell.execute_reply.started": "2025-08-16T10:24:36.280725Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df['Age'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:24:41.573605Z",
     "iopub.status.busy": "2025-08-16T10:24:41.573046Z",
     "iopub.status.idle": "2025-08-16T10:24:42.422063Z",
     "shell.execute_reply": "2025-08-16T10:24:42.421295Z",
     "shell.execute_reply.started": "2025-08-16T10:24:41.573580Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Understanding the distribution of the column - Age\n",
    "\n",
    "sns.distplot(credit_df['Age'], \n",
    "            label = 'Skewness: %.2f'%(credit_df['Age'].skew())\n",
    "           )\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Customer Age Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:24:46.889406Z",
     "iopub.status.busy": "2025-08-16T10:24:46.889133Z",
     "iopub.status.idle": "2025-08-16T10:24:46.895630Z",
     "shell.execute_reply": "2025-08-16T10:24:46.894898Z",
     "shell.execute_reply.started": "2025-08-16T10:24:46.889386Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This is tell us in our dataset we have the negative values or not\n",
    "(credit_df['Age'] < 0).any()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:24:48.122897Z",
     "iopub.status.busy": "2025-08-16T10:24:48.122081Z",
     "iopub.status.idle": "2025-08-16T10:24:48.129082Z",
     "shell.execute_reply": "2025-08-16T10:24:48.128268Z",
     "shell.execute_reply.started": "2025-08-16T10:24:48.122869Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# It's tell us how many negative values we have in our dataset\n",
    "(credit_df['Age'] < 0).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Yeo-Johnson transformation â€” a more flexible method that can handle zero and negative values without shifting:\n",
    "Here we use the Yeo-Johnson Methode because we have the negative values to solve this thing we use this methode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:24:52.905738Z",
     "iopub.status.busy": "2025-08-16T10:24:52.905115Z",
     "iopub.status.idle": "2025-08-16T10:24:53.978268Z",
     "shell.execute_reply": "2025-08-16T10:24:53.977418Z",
     "shell.execute_reply.started": "2025-08-16T10:24:52.905712Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Understanding the distribution of the data log(Age)\n",
    "# Applying log Transformation\n",
    "# modified_age = [np.log(age) if age > 0 else 0 for age in train_df['Age']]\n",
    "# train_df['Age'] = modified_age\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "pt = PowerTransformer(method='yeo-johnson')\n",
    "credit_df['Age'] = pt.fit_transform(credit_df[['Age']])\n",
    "\n",
    "sns.distplot(credit_df['Age'], label = 'Skewness: %.2f'%(credit_df['Age'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Customer Age Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, we can see that the degree of skewness is significantly reduced than compared to the skewness in the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4.2 Log Transforming the column - Monthly_Inhand_Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:25:02.423767Z",
     "iopub.status.busy": "2025-08-16T10:25:02.423414Z",
     "iopub.status.idle": "2025-08-16T10:25:03.243016Z",
     "shell.execute_reply": "2025-08-16T10:25:03.242158Z",
     "shell.execute_reply.started": "2025-08-16T10:25:02.423744Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Understanding the distribution of the column - Monthly_Inhand_Salary\n",
    "\n",
    "sns.distplot(credit_df['Monthly_Inhand_Salary'], label = 'Skewness: %.2f'%(credit_df['Monthly_Inhand_Salary'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Customer Monthly Inhand Salary Distribution')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:25:04.212947Z",
     "iopub.status.busy": "2025-08-16T10:25:04.212321Z",
     "iopub.status.idle": "2025-08-16T10:25:04.218280Z",
     "shell.execute_reply": "2025-08-16T10:25:04.217678Z",
     "shell.execute_reply.started": "2025-08-16T10:25:04.212923Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This is tell us in our dataset we have the negative values or not\n",
    "(credit_df['Monthly_Inhand_Salary'] < 0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:25:06.956800Z",
     "iopub.status.busy": "2025-08-16T10:25:06.956216Z",
     "iopub.status.idle": "2025-08-16T10:25:06.962744Z",
     "shell.execute_reply": "2025-08-16T10:25:06.961916Z",
     "shell.execute_reply.started": "2025-08-16T10:25:06.956772Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# It's tell us how many negative values we have in our dataset\n",
    "(credit_df['Monthly_Inhand_Salary'] < 0).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:25:08.738743Z",
     "iopub.status.busy": "2025-08-16T10:25:08.738417Z",
     "iopub.status.idle": "2025-08-16T10:25:09.796174Z",
     "shell.execute_reply": "2025-08-16T10:25:09.795354Z",
     "shell.execute_reply.started": "2025-08-16T10:25:08.738718Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Understanding the distribution of the data log(Monthly_Inhand_Salary)\n",
    "\n",
    "modified_salary = [np.log(salary) if salary > 0 else 0 for salary in credit_df['Monthly_Inhand_Salary']]\n",
    "credit_df['Monthly_Inhand_Salary'] = modified_salary\n",
    "\n",
    "sns.distplot(credit_df['Monthly_Inhand_Salary'], label = 'Skewness: %.2f'%(credit_df['Monthly_Inhand_Salary'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Customer Monthly Inhand Salary Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, we can see that the degree of skewness is significantly reduced than compared to the skewness in the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4.3 Log Transforming the column - Interest_Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:25:14.034040Z",
     "iopub.status.busy": "2025-08-16T10:25:14.033279Z",
     "iopub.status.idle": "2025-08-16T10:25:14.040104Z",
     "shell.execute_reply": "2025-08-16T10:25:14.039399Z",
     "shell.execute_reply.started": "2025-08-16T10:25:14.034013Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df['Interest_Rate'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:25:15.456791Z",
     "iopub.status.busy": "2025-08-16T10:25:15.456456Z",
     "iopub.status.idle": "2025-08-16T10:25:16.327201Z",
     "shell.execute_reply": "2025-08-16T10:25:16.326291Z",
     "shell.execute_reply.started": "2025-08-16T10:25:15.456768Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Understanding the distribution of the column - Interest_Rate\n",
    "\n",
    "sns.distplot(credit_df['Interest_Rate'], label = 'Skewness: %.2f'%(credit_df['Interest_Rate'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Interest Rate Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:25:17.191306Z",
     "iopub.status.busy": "2025-08-16T10:25:17.190457Z",
     "iopub.status.idle": "2025-08-16T10:25:17.196972Z",
     "shell.execute_reply": "2025-08-16T10:25:17.196229Z",
     "shell.execute_reply.started": "2025-08-16T10:25:17.191263Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "(credit_df['Interest_Rate'] < 0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:25:19.655959Z",
     "iopub.status.busy": "2025-08-16T10:25:19.655292Z",
     "iopub.status.idle": "2025-08-16T10:25:19.662015Z",
     "shell.execute_reply": "2025-08-16T10:25:19.661244Z",
     "shell.execute_reply.started": "2025-08-16T10:25:19.655933Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "(credit_df['Interest_Rate'] < 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:25:21.013732Z",
     "iopub.status.busy": "2025-08-16T10:25:21.013383Z",
     "iopub.status.idle": "2025-08-16T10:25:22.014613Z",
     "shell.execute_reply": "2025-08-16T10:25:22.013787Z",
     "shell.execute_reply.started": "2025-08-16T10:25:21.013708Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Understanding the distribution of the data log(Interest_Rate)\n",
    "\n",
    "modified_interest = [np.log(interest) if interest > 0 else 0 for interest in credit_df['Interest_Rate']]\n",
    "credit_df['Interest_Rate'] = modified_interest\n",
    "\n",
    "sns.distplot(credit_df['Interest_Rate'], label = 'Skewness: %.2f'%(credit_df['Interest_Rate'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Interest Rate Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, we can see that the degree of skewness is significantly reduced than compared to the skewness in the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4.4 Log Transforming the column - Num_of_Delayed_Payment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:25:25.326012Z",
     "iopub.status.busy": "2025-08-16T10:25:25.325744Z",
     "iopub.status.idle": "2025-08-16T10:25:26.165329Z",
     "shell.execute_reply": "2025-08-16T10:25:26.164529Z",
     "shell.execute_reply.started": "2025-08-16T10:25:25.325992Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Understanding the distribution of the column - Num_of_Delayed_Payment\n",
    "\n",
    "sns.distplot(credit_df['Num_of_Delayed_Payment'], label = 'Skewness: %.2f'%(credit_df['Num_of_Delayed_Payment'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Delayed Payment Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:25:27.048969Z",
     "iopub.status.busy": "2025-08-16T10:25:27.048330Z",
     "iopub.status.idle": "2025-08-16T10:25:27.054454Z",
     "shell.execute_reply": "2025-08-16T10:25:27.053844Z",
     "shell.execute_reply.started": "2025-08-16T10:25:27.048943Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "(credit_df['Num_of_Delayed_Payment']<0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:25:29.128510Z",
     "iopub.status.busy": "2025-08-16T10:25:29.128202Z",
     "iopub.status.idle": "2025-08-16T10:25:29.134613Z",
     "shell.execute_reply": "2025-08-16T10:25:29.133826Z",
     "shell.execute_reply.started": "2025-08-16T10:25:29.128487Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "(credit_df['Num_of_Delayed_Payment']<0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:25:30.530924Z",
     "iopub.status.busy": "2025-08-16T10:25:30.530642Z",
     "iopub.status.idle": "2025-08-16T10:25:31.461081Z",
     "shell.execute_reply": "2025-08-16T10:25:31.460269Z",
     "shell.execute_reply.started": "2025-08-16T10:25:30.530903Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Understanding the distribution of the data log(Num_of_Delayed_Payment)\n",
    "\n",
    "modified_payment = [np.log(payment) if payment > 0 else 0 for payment in credit_df['Num_of_Delayed_Payment']]\n",
    "credit_df['Num_of_Delayed_Payment'] = modified_payment\n",
    "\n",
    "sns.distplot(credit_df['Num_of_Delayed_Payment'], label = 'Skewness: %.2f'%(credit_df['Num_of_Delayed_Payment'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Delayed Payment Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, we can see that the degree of skewness is significantly reduced than compared to the skewness in the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4.5 Log Transforming the column - Num_Credit_Inquiries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:25:48.038189Z",
     "iopub.status.busy": "2025-08-16T10:25:48.037397Z",
     "iopub.status.idle": "2025-08-16T10:25:48.897333Z",
     "shell.execute_reply": "2025-08-16T10:25:48.896520Z",
     "shell.execute_reply.started": "2025-08-16T10:25:48.038164Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Understanding the distribution of the column - Num_Credit_Inquiries\n",
    "\n",
    "sns.distplot(credit_df['Num_Credit_Inquiries'], label = 'Skewness: %.2f'%(credit_df['Num_Credit_Inquiries'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Number of Credit Inquiries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:25:49.733210Z",
     "iopub.status.busy": "2025-08-16T10:25:49.732922Z",
     "iopub.status.idle": "2025-08-16T10:25:49.739761Z",
     "shell.execute_reply": "2025-08-16T10:25:49.738938Z",
     "shell.execute_reply.started": "2025-08-16T10:25:49.733188Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "(credit_df['Num_Credit_Inquiries']<0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:25:52.154047Z",
     "iopub.status.busy": "2025-08-16T10:25:52.153311Z",
     "iopub.status.idle": "2025-08-16T10:25:52.159732Z",
     "shell.execute_reply": "2025-08-16T10:25:52.158945Z",
     "shell.execute_reply.started": "2025-08-16T10:25:52.154019Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "(credit_df['Num_Credit_Inquiries']<0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:25:53.769629Z",
     "iopub.status.busy": "2025-08-16T10:25:53.768903Z",
     "iopub.status.idle": "2025-08-16T10:25:53.776244Z",
     "shell.execute_reply": "2025-08-16T10:25:53.775407Z",
     "shell.execute_reply.started": "2025-08-16T10:25:53.769602Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "(credit_df['Num_Credit_Inquiries']).skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:25:55.518453Z",
     "iopub.status.busy": "2025-08-16T10:25:55.517725Z",
     "iopub.status.idle": "2025-08-16T10:25:56.438260Z",
     "shell.execute_reply": "2025-08-16T10:25:56.437447Z",
     "shell.execute_reply.started": "2025-08-16T10:25:55.518426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Understanding the distribution of the data log(Num_Credit_Inquiries)\n",
    "\n",
    "modified_inquiries = [np.log(inquiries) if inquiries > 0 else 0 for inquiries in credit_df['Num_Credit_Inquiries']]\n",
    "credit_df['Num_Credit_Inquiries'] = modified_inquiries\n",
    "\n",
    "sns.distplot(credit_df['Num_Credit_Inquiries'], label = 'Skewness: %.2f'%(credit_df['Num_Credit_Inquiries'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Number of Credit Card Inquiries')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, we can see that the degree of skewness is significantly reduced than compared to the skewness in the original data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4.6 Log Transforming the column - Total_EMI_per_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:26:00.497226Z",
     "iopub.status.busy": "2025-08-16T10:26:00.496536Z",
     "iopub.status.idle": "2025-08-16T10:26:01.335522Z",
     "shell.execute_reply": "2025-08-16T10:26:01.334768Z",
     "shell.execute_reply.started": "2025-08-16T10:26:00.497189Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Understanding the distribution of the column - Total_EMI_per_month\n",
    "\n",
    "sns.distplot(credit_df['Total_EMI_per_month'], label = 'Skewness: %.2f'%(credit_df['Total_EMI_per_month'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Total EMI per month Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:26:02.118602Z",
     "iopub.status.busy": "2025-08-16T10:26:02.117896Z",
     "iopub.status.idle": "2025-08-16T10:26:02.124147Z",
     "shell.execute_reply": "2025-08-16T10:26:02.123293Z",
     "shell.execute_reply.started": "2025-08-16T10:26:02.118576Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "(credit_df['Total_EMI_per_month']<0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:26:04.767182Z",
     "iopub.status.busy": "2025-08-16T10:26:04.766920Z",
     "iopub.status.idle": "2025-08-16T10:26:04.773617Z",
     "shell.execute_reply": "2025-08-16T10:26:04.772860Z",
     "shell.execute_reply.started": "2025-08-16T10:26:04.767163Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "(credit_df['Total_EMI_per_month']<0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:26:06.682157Z",
     "iopub.status.busy": "2025-08-16T10:26:06.681862Z",
     "iopub.status.idle": "2025-08-16T10:26:07.584501Z",
     "shell.execute_reply": "2025-08-16T10:26:07.583656Z",
     "shell.execute_reply.started": "2025-08-16T10:26:06.682133Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Understanding the distribution of the data log(Total_EMI_per_month)\n",
    "\n",
    "modified_emi = [np.log(emi) if emi > 0 else 0 for emi in credit_df['Total_EMI_per_month']]\n",
    "credit_df['Total_EMI_per_month'] = modified_emi\n",
    "\n",
    "sns.distplot(credit_df['Total_EMI_per_month'], label = 'Skewness: %.2f'%(credit_df['Total_EMI_per_month'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Total EMI per month Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, we can see that the degree of skewness is significantly reduced than compared to the skewness in the original data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4.7 Log Transforming the column - Amount_invested_monthly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:26:12.273731Z",
     "iopub.status.busy": "2025-08-16T10:26:12.272941Z",
     "iopub.status.idle": "2025-08-16T10:26:13.146014Z",
     "shell.execute_reply": "2025-08-16T10:26:13.145243Z",
     "shell.execute_reply.started": "2025-08-16T10:26:12.273701Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Understanding the distribution of the column - Amount_invested_monthly\n",
    "\n",
    "sns.distplot(credit_df['Amount_invested_monthly'], label = 'Skewness: %.2f'%(credit_df['Amount_invested_monthly'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Amount invested monthly Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:26:15.101634Z",
     "iopub.status.busy": "2025-08-16T10:26:15.100897Z",
     "iopub.status.idle": "2025-08-16T10:26:15.106829Z",
     "shell.execute_reply": "2025-08-16T10:26:15.106186Z",
     "shell.execute_reply.started": "2025-08-16T10:26:15.101605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "(credit_df['Amount_invested_monthly']<0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:26:17.659047Z",
     "iopub.status.busy": "2025-08-16T10:26:17.658754Z",
     "iopub.status.idle": "2025-08-16T10:26:17.665782Z",
     "shell.execute_reply": "2025-08-16T10:26:17.664944Z",
     "shell.execute_reply.started": "2025-08-16T10:26:17.659026Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "(credit_df['Amount_invested_monthly']<0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:26:19.181676Z",
     "iopub.status.busy": "2025-08-16T10:26:19.181286Z",
     "iopub.status.idle": "2025-08-16T10:26:20.136073Z",
     "shell.execute_reply": "2025-08-16T10:26:20.135268Z",
     "shell.execute_reply.started": "2025-08-16T10:26:19.181651Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Understanding the distribution of the data log(Total_EMI_per_month)\n",
    "\n",
    "modified_emi = [np.log(emi) if emi > 0 else 0 for emi in credit_df['Amount_invested_monthly']]\n",
    "credit_df['Amount_invested_monthly'] = modified_emi\n",
    "\n",
    "sns.distplot(credit_df['Amount_invested_monthly'], label = 'Skewness: %.2f'%(credit_df['Amount_invested_monthly'].skew()))\n",
    "plt.legend(loc = 'best')\n",
    "plt.title('Amount Invested Monthly Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph, we can see that the degree of skewness is significantly reduced than compared to the skewness in the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:26:23.909557Z",
     "iopub.status.busy": "2025-08-16T10:26:23.908758Z",
     "iopub.status.idle": "2025-08-16T10:26:23.930894Z",
     "shell.execute_reply": "2025-08-16T10:26:23.930013Z",
     "shell.execute_reply.started": "2025-08-16T10:26:23.909523Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.5 Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature encoding is the process of turning categorical data in a dataset into numerical data. It is essential that we perform feature encoding because most machine learning models can only interpret numerical data and not data in text form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:32:19.345809Z",
     "iopub.status.busy": "2025-08-16T10:32:19.345439Z",
     "iopub.status.idle": "2025-08-16T10:32:19.422937Z",
     "shell.execute_reply": "2025-08-16T10:32:19.422091Z",
     "shell.execute_reply.started": "2025-08-16T10:32:19.345786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### One Hot Encoding the columns - Month, Occupation, Payment_of_Min_Amount of the dataset\n",
    "# Here we are not doing for the credit score column because that is our target columns\n",
    "encoded_dataset = pd.get_dummies(data = credit_df, \n",
    "                                       columns = ['Month', 'Occupation', 'Payment_of_Min_Amount'])\n",
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:32:41.351827Z",
     "iopub.status.busy": "2025-08-16T10:32:41.351526Z",
     "iopub.status.idle": "2025-08-16T10:32:41.364571Z",
     "shell.execute_reply": "2025-08-16T10:32:41.363726Z",
     "shell.execute_reply.started": "2025-08-16T10:32:41.351805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Encoding the Credit Score (Target) column\n",
    "mapping = {'Poor': 0, 'Standard': 1, 'Good': 2}\n",
    "encoded_dataset['Target'] = encoded_dataset['Credit_Score'].map(mapping)\n",
    "encoded_dataset.drop(['Credit_Score'], axis=1, inplace=True) # Here we drop the Credit_Score col and make another column the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:32:50.375792Z",
     "iopub.status.busy": "2025-08-16T10:32:50.375495Z",
     "iopub.status.idle": "2025-08-16T10:32:50.406785Z",
     "shell.execute_reply": "2025-08-16T10:32:50.406001Z",
     "shell.execute_reply.started": "2025-08-16T10:32:50.375770Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Looking at the dataset\n",
    "\n",
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:33:02.650158Z",
     "iopub.status.busy": "2025-08-16T10:33:02.649864Z",
     "iopub.status.idle": "2025-08-16T10:33:02.657965Z",
     "shell.execute_reply": "2025-08-16T10:33:02.657252Z",
     "shell.execute_reply.started": "2025-08-16T10:33:02.650136Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "encoded_dataset['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:35:54.077040Z",
     "iopub.status.busy": "2025-08-16T10:35:54.076492Z",
     "iopub.status.idle": "2025-08-16T10:35:54.098030Z",
     "shell.execute_reply": "2025-08-16T10:35:54.097287Z",
     "shell.execute_reply.started": "2025-08-16T10:35:54.077018Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "encoded_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:36:18.754142Z",
     "iopub.status.busy": "2025-08-16T10:36:18.753338Z",
     "iopub.status.idle": "2025-08-16T10:36:18.768531Z",
     "shell.execute_reply": "2025-08-16T10:36:18.767867Z",
     "shell.execute_reply.started": "2025-08-16T10:36:18.754115Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "credit_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:36:52.551761Z",
     "iopub.status.busy": "2025-08-16T10:36:52.551425Z",
     "iopub.status.idle": "2025-08-16T10:36:52.588030Z",
     "shell.execute_reply": "2025-08-16T10:36:52.587264Z",
     "shell.execute_reply.started": "2025-08-16T10:36:52.551738Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set the display option to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Now, filter and display your DataFrame\n",
    "Zero_encoded_dataset = encoded_dataset[encoded_dataset['Target'] == 0]  # Poor: 0\n",
    "\n",
    "# This will now print all the columns without skipping any\n",
    "Zero_encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:37:40.515720Z",
     "iopub.status.busy": "2025-08-16T10:37:40.515091Z",
     "iopub.status.idle": "2025-08-16T10:37:40.553404Z",
     "shell.execute_reply": "2025-08-16T10:37:40.552621Z",
     "shell.execute_reply.started": "2025-08-16T10:37:40.515695Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set the display option to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Now, filter and display your DataFrame\n",
    "One_encoded_dataset = encoded_dataset[encoded_dataset['Target'] == 1] # Standard: 1\n",
    "\n",
    "# This will now print all the columns without skipping any\n",
    "One_encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:38:09.241574Z",
     "iopub.status.busy": "2025-08-16T10:38:09.241241Z",
     "iopub.status.idle": "2025-08-16T10:38:09.276258Z",
     "shell.execute_reply": "2025-08-16T10:38:09.275391Z",
     "shell.execute_reply.started": "2025-08-16T10:38:09.241551Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set the display option to show all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Now, filter and display your DataFrame\n",
    "Two_encoded_dataset = encoded_dataset[encoded_dataset['Target'] == 2] # Good: 2\n",
    "\n",
    "# This will now print all the columns without skipping any\n",
    "Two_encoded_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our datasets are ready for modelling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn is one of the most popular libraries for machine learning in Python and that is what we will use in the modelling part of this project.\n",
    "\n",
    "Since Credit Score detection is a classfication problem, we will need to use classfication models, also known as classifiers, to train on our model to make predictions. I highly recommend checking out the scikit-learn documentation for more information on the different machine learning models available in their library. I have chosen the following classifiers for the job:\n",
    "\n",
    "1. Logistic regression\n",
    "2. Support vector classification\n",
    "3. K-nearest neighbours\n",
    "4. Naive Bayes\n",
    "5. Decision tree\n",
    "6. Random forest\n",
    "   \n",
    "Here, we will only be focusing on the data belonging to Good and Poor credit scores.\n",
    "\n",
    "In this section of the notebook, I will fit the models to the training set as outlined above and evaluate their accuracy at making predictions. Once the best model is determined, I will also do hyperparameter tuning to further boost the performance of the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.values` â†’ converts the DataFrame slice into a NumPy array (machine learning models usually need NumPy arrays instead of DataFrames)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:41:37.961777Z",
     "iopub.status.busy": "2025-08-16T10:41:37.961115Z",
     "iopub.status.idle": "2025-08-16T10:41:38.089181Z",
     "shell.execute_reply": "2025-08-16T10:41:38.088408Z",
     "shell.execute_reply.started": "2025-08-16T10:41:37.961741Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Splitting the data to the matrices X and Y using the training set.\n",
    "X = encoded_dataset.iloc[:, : -1].values # It means here we are taking all the rows and column except the last column(Target)\n",
    "Y = encoded_dataset.iloc[:, -1].values # Here we are taking all the rows and only taking the last column(Target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:41:38.771253Z",
     "iopub.status.busy": "2025-08-16T10:41:38.770533Z",
     "iopub.status.idle": "2025-08-16T10:41:38.776199Z",
     "shell.execute_reply": "2025-08-16T10:41:38.775513Z",
     "shell.execute_reply.started": "2025-08-16T10:41:38.771228Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Looking at the new training data - X\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:41:41.414782Z",
     "iopub.status.busy": "2025-08-16T10:41:41.414444Z",
     "iopub.status.idle": "2025-08-16T10:41:41.420683Z",
     "shell.execute_reply": "2025-08-16T10:41:41.419871Z",
     "shell.execute_reply.started": "2025-08-16T10:41:41.414760Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Looking at the new test data - Y\n",
    "\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:41:42.801254Z",
     "iopub.status.busy": "2025-08-16T10:41:42.800995Z",
     "iopub.status.idle": "2025-08-16T10:41:42.886779Z",
     "shell.execute_reply": "2025-08-16T10:41:42.885889Z",
     "shell.execute_reply.started": "2025-08-16T10:41:42.801234Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:41:44.214341Z",
     "iopub.status.busy": "2025-08-16T10:41:44.214056Z",
     "iopub.status.idle": "2025-08-16T10:41:44.733186Z",
     "shell.execute_reply": "2025-08-16T10:41:44.732589Z",
     "shell.execute_reply.started": "2025-08-16T10:41:44.214319Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Dividing the dataset into train and test in the ratio of 70 : 30\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 27) #, shuffle = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:41:45.544610Z",
     "iopub.status.busy": "2025-08-16T10:41:45.543985Z",
     "iopub.status.idle": "2025-08-16T10:41:45.549614Z",
     "shell.execute_reply": "2025-08-16T10:41:45.548918Z",
     "shell.execute_reply.started": "2025-08-16T10:41:45.544584Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:41:47.303497Z",
     "iopub.status.busy": "2025-08-16T10:41:47.302938Z",
     "iopub.status.idle": "2025-08-16T10:41:47.308920Z",
     "shell.execute_reply": "2025-08-16T10:41:47.307991Z",
     "shell.execute_reply.started": "2025-08-16T10:41:47.303450Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:41:49.294980Z",
     "iopub.status.busy": "2025-08-16T10:41:49.294146Z",
     "iopub.status.idle": "2025-08-16T10:41:49.301235Z",
     "shell.execute_reply": "2025-08-16T10:41:49.300391Z",
     "shell.execute_reply.started": "2025-08-16T10:41:49.294952Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:41:50.832006Z",
     "iopub.status.busy": "2025-08-16T10:41:50.831324Z",
     "iopub.status.idle": "2025-08-16T10:41:50.838134Z",
     "shell.execute_reply": "2025-08-16T10:41:50.837386Z",
     "shell.execute_reply.started": "2025-08-16T10:41:50.831977Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:41:52.781722Z",
     "iopub.status.busy": "2025-08-16T10:41:52.781054Z",
     "iopub.status.idle": "2025-08-16T10:41:52.785825Z",
     "shell.execute_reply": "2025-08-16T10:41:52.784860Z",
     "shell.execute_reply.started": "2025-08-16T10:41:52.781695Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:41:54.311317Z",
     "iopub.status.busy": "2025-08-16T10:41:54.310820Z",
     "iopub.status.idle": "2025-08-16T10:41:54.315260Z",
     "shell.execute_reply": "2025-08-16T10:41:54.314415Z",
     "shell.execute_reply.started": "2025-08-16T10:41:54.311292Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Dictionary to store model and its accuracy\n",
    "\n",
    "model_accuracy = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:41:55.107616Z",
     "iopub.status.busy": "2025-08-16T10:41:55.107301Z",
     "iopub.status.idle": "2025-08-16T10:41:55.111846Z",
     "shell.execute_reply": "2025-08-16T10:41:55.110889Z",
     "shell.execute_reply.started": "2025-08-16T10:41:55.107591Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Dictionary to store model and its precision\n",
    "\n",
    "model_precision = OrderedDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:41:55.672505Z",
     "iopub.status.busy": "2025-08-16T10:41:55.672221Z",
     "iopub.status.idle": "2025-08-16T10:41:55.676438Z",
     "shell.execute_reply": "2025-08-16T10:41:55.675609Z",
     "shell.execute_reply.started": "2025-08-16T10:41:55.672486Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Dictionary to store model and its recall\n",
    "\n",
    "model_recall = OrderedDict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.1 Applying Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:42:00.255284Z",
     "iopub.status.busy": "2025-08-16T10:42:00.254994Z",
     "iopub.status.idle": "2025-08-16T10:42:00.346634Z",
     "shell.execute_reply": "2025-08-16T10:42:00.345842Z",
     "shell.execute_reply.started": "2025-08-16T10:42:00.255261Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:42:01.163186Z",
     "iopub.status.busy": "2025-08-16T10:42:01.162928Z",
     "iopub.status.idle": "2025-08-16T10:42:04.689720Z",
     "shell.execute_reply": "2025-08-16T10:42:04.688958Z",
     "shell.execute_reply.started": "2025-08-16T10:42:01.163168Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Training the Logistic Regression model on the dataset\n",
    "\n",
    "logistic_classifier = LogisticRegression(random_state = 27) # Here our model putting into the variable\n",
    "logistic_classifier.fit(X_train, Y_train) # Fitting our model to our X_train & Y_train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:42:04.692181Z",
     "iopub.status.busy": "2025-08-16T10:42:04.691925Z",
     "iopub.status.idle": "2025-08-16T10:42:04.786160Z",
     "shell.execute_reply": "2025-08-16T10:42:04.785410Z",
     "shell.execute_reply.started": "2025-08-16T10:42:04.692160Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = logistic_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:42:04.787208Z",
     "iopub.status.busy": "2025-08-16T10:42:04.786946Z",
     "iopub.status.idle": "2025-08-16T10:42:04.799836Z",
     "shell.execute_reply": "2025-08-16T10:42:04.798968Z",
     "shell.execute_reply.started": "2025-08-16T10:42:04.787180Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Here it's telling the what is the actual values and the prediction values\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:42:07.299500Z",
     "iopub.status.busy": "2025-08-16T10:42:07.298744Z",
     "iopub.status.idle": "2025-08-16T10:42:07.303238Z",
     "shell.execute_reply": "2025-08-16T10:42:07.302404Z",
     "shell.execute_reply.started": "2025-08-16T10:42:07.299450Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:42:14.474920Z",
     "iopub.status.busy": "2025-08-16T10:42:14.474622Z",
     "iopub.status.idle": "2025-08-16T10:42:14.504172Z",
     "shell.execute_reply": "2025-08-16T10:42:14.503544Z",
     "shell.execute_reply.started": "2025-08-16T10:42:14.474899Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy, precision, and recall of the model\n",
    "\n",
    "logistic_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_accuracy['Logistic Regression'] = logistic_accuracy\n",
    "\n",
    "logistic_precision = round(100 * precision_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_precision['Logistic Regression'] = logistic_precision\n",
    "\n",
    "logistic_recall = round(100 * recall_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_recall['Logistic Regression'] = logistic_recall\n",
    "\n",
    "print('The accuracy of this model is {} %.'.format(logistic_accuracy))\n",
    "print('The precision of this model is {} %.'.format(logistic_precision))\n",
    "print('The recall of this model is {} %.'.format(logistic_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class-by-class breakdown of `confusion_matrix`\n",
    "\n",
    "Class 0 (row 0)\n",
    "\n",
    "    Correctly predicted as class 0 â†’ 3597\n",
    "    Wrongly predicted as class 1 â†’ 4867\n",
    "    Wrongly predicted as class 2 â†’ 200\n",
    "\n",
    "Class 1 (row 1)\n",
    "\n",
    "    Correctly predicted as class 1 â†’ 12946\n",
    "    Wrongly predicted as class 0 â†’ 1898\n",
    "    Wrongly predicted as class 2 â†’ 1040\n",
    "\n",
    "Class 2 (row 2)\n",
    "\n",
    "    Correctly predicted as class 2 â†’ 1273\n",
    "    Wrongly predicted as class 0 â†’ 78\n",
    "    Wrongly predicted as class 1 â†’ 3956"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`confusion_matrix` â†’ table showing correct vs. wrong predictions.\n",
    "\n",
    "`accuracy` â†’ overall score (how often youâ€™re right).\n",
    "\n",
    "`precision` â†’ when you predict something, how often itâ€™s correct.\n",
    "\n",
    "`recall` â†’ how well you find all actual positives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.2 Applying SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T12:25:45.282899Z",
     "iopub.status.busy": "2025-08-15T12:25:45.282619Z",
     "iopub.status.idle": "2025-08-15T12:25:45.286438Z",
     "shell.execute_reply": "2025-08-15T12:25:45.285662Z",
     "shell.execute_reply.started": "2025-08-15T12:25:45.282879Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.875Z",
     "iopub.execute_input": "2025-08-15T12:25:45.287545Z",
     "iopub.status.busy": "2025-08-15T12:25:45.287188Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Applying SVM Classification model (RBF kernel)\n",
    "svm_classifier = SVC(kernel='rbf', random_state=27)\n",
    "svm_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.875Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Predicting the Test set results\n",
    "Y_pred = svm_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Making the confusion matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy, precision, and recall of the model\n",
    "svm_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_accuracy['SVM (RBF kernel)'] = svm_accuracy\n",
    "\n",
    "svm_precision = round(100 * precision_score(Y_test, Y_pred, average='weighted'), 2)\n",
    "model_precision['SVM (RBF kernel)'] = svm_precision\n",
    "\n",
    "svm_recall = round(100 * recall_score(Y_test, Y_pred, average='weighted'), 2)\n",
    "model_recall['SVM (RBF kernel)'] = svm_recall\n",
    "\n",
    "print('The accuracy of this model is {} %.'.format(svm_accuracy))\n",
    "print('The precision of this model is {} %.'.format(svm_precision))\n",
    "print('The recall of this model is {} %.'.format(svm_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:42:26.670576Z",
     "iopub.status.busy": "2025-08-16T10:42:26.670261Z",
     "iopub.status.idle": "2025-08-16T10:42:26.775831Z",
     "shell.execute_reply": "2025-08-16T10:42:26.775151Z",
     "shell.execute_reply.started": "2025-08-16T10:42:26.670554Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know that forKNN algo we need optimal k value so,For that below this code is writing for the optimal k value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "error_rates = []\n",
    "\n",
    "# Calculate error rates for k = 1 to 30\n",
    "for k in range(1, 31):\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    Y_pred = knn.predict(X_test)\n",
    "    error_rates.append(1 - accuracy_score(Y_test, Y_pred))\n",
    "\n",
    "# Find optimal k\n",
    "optimal_k = range(1, 31)[error_rates.index(min(error_rates))]\n",
    "#print(\"Optimal K is:\", optimal_k)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, 31), error_rates, color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=8)\n",
    "\n",
    "# Draw red vertical line at optimal k\n",
    "plt.axvline(x=optimal_k, color='red', linestyle='--', linewidth=2, label=f'Optimal k = {optimal_k}')\n",
    "\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.title('Error Rate vs K Value')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we got our optimal k value which is `4`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will implement on our model so before directly putting the 4 we will also explore that this is correct or not and we will put the surrounding values of this like: 1,3 and 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.3 Applying K-Nearest Neighbors (k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:42:32.676329Z",
     "iopub.status.busy": "2025-08-16T10:42:32.675775Z",
     "iopub.status.idle": "2025-08-16T10:42:32.909609Z",
     "shell.execute_reply": "2025-08-16T10:42:32.908870Z",
     "shell.execute_reply.started": "2025-08-16T10:42:32.676307Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Applying 1NN model\n",
    "\n",
    "classifier_1nn = KNeighborsClassifier(n_neighbors = 1, algorithm = 'auto', p = 2, metric = 'minkowski')\n",
    "classifier_1nn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:42:34.529143Z",
     "iopub.status.busy": "2025-08-16T10:42:34.528853Z",
     "iopub.status.idle": "2025-08-16T10:42:39.611751Z",
     "shell.execute_reply": "2025-08-16T10:42:39.610578Z",
     "shell.execute_reply.started": "2025-08-16T10:42:34.529120Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = classifier_1nn.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:42:39.613271Z",
     "iopub.status.busy": "2025-08-16T10:42:39.613013Z",
     "iopub.status.idle": "2025-08-16T10:42:39.641633Z",
     "shell.execute_reply": "2025-08-16T10:42:39.640766Z",
     "shell.execute_reply.started": "2025-08-16T10:42:39.613252Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy, precision, and recall of the model\n",
    "\n",
    "nn1_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_accuracy['1 - Nearest Neighbors'] = nn1_accuracy\n",
    "\n",
    "nn1_precision = round(100 * precision_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_precision['1 - Nearest Neighbors'] = nn1_precision\n",
    "\n",
    "nn1_recall = round(100 * recall_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_recall['1 - Nearest Neighbors'] = nn1_recall\n",
    "\n",
    "print('The accuracy of this model is {} %.'.format(nn1_accuracy))\n",
    "print('The precision of this model is {} %.'.format(nn1_precision))\n",
    "print('The recall of this model is {} %.'.format(nn1_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.4 Applying K - Nearest Neighbors (k = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.877Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Applying 3NN model\n",
    "\n",
    "classifier_3nn = KNeighborsClassifier(n_neighbors = 3, algorithm = 'auto', p = 2, metric = 'minkowski')\n",
    "classifier_3nn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.877Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = classifier_3nn.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.877Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy, precision, and recall of the model\n",
    "\n",
    "nn3_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_accuracy['3 - Nearest Neighbors'] = nn3_accuracy\n",
    "\n",
    "nn3_precision = round(100 * precision_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_precision['3 - Nearest Neighbors'] = nn3_precision\n",
    "\n",
    "nn3_recall = round(100 * recall_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_recall['3 - Nearest Neighbors'] = nn3_recall\n",
    "\n",
    "print('The accuracy of this model is {} %.'.format(nn3_accuracy))\n",
    "print('The precision of this model is {} %.'.format(nn3_precision))\n",
    "print('The recall of this model is {} %.'.format(nn3_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.5 Applying K - Nearest Neighbors (k = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:42:45.648963Z",
     "iopub.status.busy": "2025-08-16T10:42:45.648657Z",
     "iopub.status.idle": "2025-08-16T10:42:45.882129Z",
     "shell.execute_reply": "2025-08-16T10:42:45.881196Z",
     "shell.execute_reply.started": "2025-08-16T10:42:45.648939Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Applying 4NN model\n",
    "\n",
    "classifier_4nn = KNeighborsClassifier(n_neighbors = 4, algorithm = 'auto', p = 2, metric = 'minkowski')\n",
    "classifier_4nn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:42:47.053800Z",
     "iopub.status.busy": "2025-08-16T10:42:47.053035Z",
     "iopub.status.idle": "2025-08-16T10:42:52.181105Z",
     "shell.execute_reply": "2025-08-16T10:42:52.180139Z",
     "shell.execute_reply.started": "2025-08-16T10:42:47.053770Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = classifier_4nn.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:42:52.182611Z",
     "iopub.status.busy": "2025-08-16T10:42:52.182332Z",
     "iopub.status.idle": "2025-08-16T10:42:52.211454Z",
     "shell.execute_reply": "2025-08-16T10:42:52.210780Z",
     "shell.execute_reply.started": "2025-08-16T10:42:52.182591Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy, precision, and recall of the model\n",
    "\n",
    "nn4_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_accuracy['4 - Nearest Neighbors'] = nn4_accuracy\n",
    "\n",
    "nn4_precision = round(100 * precision_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_precision['4 - Nearest Neighbors'] = nn4_precision\n",
    "\n",
    "nn4_recall = round(100 * recall_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_recall['4 - Nearest Neighbors'] = nn4_recall\n",
    "\n",
    "print('The accuracy of this model is {} %.'.format(nn4_accuracy))\n",
    "print('The precision of this model is {} %.'.format(nn4_precision))\n",
    "print('The recall of this model is {} %.'.format(nn4_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.6 Applying K - Nearest Neighbors (k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Applying 5NN model\n",
    "\n",
    "classifier_5nn = KNeighborsClassifier(n_neighbors = 5, algorithm = 'auto', p = 2, metric = 'minkowski')\n",
    "classifier_5nn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = classifier_5nn.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy, precision, and recall of the model\n",
    "\n",
    "nn5_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_accuracy['5 - Nearest Neighbors'] = nn5_accuracy\n",
    "\n",
    "nn5_precision = round(100 * precision_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_precision['5 - Nearest Neighbors'] = nn5_precision\n",
    "\n",
    "nn5_recall = round(100 * recall_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_recall['5 - Nearest Neighbors'] = nn5_recall\n",
    "\n",
    "print('The accuracy of this model is {} %.'.format(nn5_accuracy))\n",
    "print('The precision of this model is {} %.'.format(nn5_precision))\n",
    "print('The recall of this model is {} %.'.format(nn5_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.878Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Looking at the accuracy graph of all the nearest neighbors\n",
    "\n",
    "labels = ['1NN', '3NN', '4NN', '5NN'] #,'optimal_knn'\n",
    "values = [nn1_accuracy, nn3_accuracy, nn4_accuracy, nn5_accuracy] #,nnoptimal_k_accuracy\n",
    "\n",
    "plt.title('Accuracies of all the nearest neighbor models')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(labels, values, '*-')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the accuracies of all the nearest neighbor models. We can see that the accuracy first increases, reaches a peak and then decreases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For knn algo for k=4 we got our best accuracy score also we can see this diagram also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.7 Applying Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:42:59.402964Z",
     "iopub.status.busy": "2025-08-16T10:42:59.402563Z",
     "iopub.status.idle": "2025-08-16T10:42:59.415231Z",
     "shell.execute_reply": "2025-08-16T10:42:59.414616Z",
     "shell.execute_reply.started": "2025-08-16T10:42:59.402942Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:43:01.060682Z",
     "iopub.status.busy": "2025-08-16T10:43:01.060226Z",
     "iopub.status.idle": "2025-08-16T10:43:01.361221Z",
     "shell.execute_reply": "2025-08-16T10:43:01.360537Z",
     "shell.execute_reply.started": "2025-08-16T10:43:01.060655Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Applying Naive Bayes Classification model\n",
    "\n",
    "naive_bayes_classifier = GaussianNB()\n",
    "naive_bayes_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:43:02.832557Z",
     "iopub.status.busy": "2025-08-16T10:43:02.832057Z",
     "iopub.status.idle": "2025-08-16T10:43:02.922207Z",
     "shell.execute_reply": "2025-08-16T10:43:02.921261Z",
     "shell.execute_reply.started": "2025-08-16T10:43:02.832529Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = naive_bayes_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:43:04.936971Z",
     "iopub.status.busy": "2025-08-16T10:43:04.936339Z",
     "iopub.status.idle": "2025-08-16T10:43:04.966420Z",
     "shell.execute_reply": "2025-08-16T10:43:04.965698Z",
     "shell.execute_reply.started": "2025-08-16T10:43:04.936942Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy, precision, and recall of the model\n",
    "\n",
    "naive_bayes_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_accuracy['Gaussian Naive Bayes'] = naive_bayes_accuracy\n",
    "\n",
    "naive_bayes_precision = round(100 * precision_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_precision['Gaussian Naive Bayes'] = naive_bayes_precision\n",
    "\n",
    "naive_bayes_recall = round(100 * recall_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_recall['Gaussian Naive Bayes'] = naive_bayes_recall\n",
    "\n",
    "print('The accuracy of this model is {} %.'.format(naive_bayes_accuracy))\n",
    "print('The precision of this model is {} %.'.format(naive_bayes_precision))\n",
    "print('The recall of this model is {} %.'.format(naive_bayes_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.8 Applying Decision Tree Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:43:09.264326Z",
     "iopub.status.busy": "2025-08-16T10:43:09.264052Z",
     "iopub.status.idle": "2025-08-16T10:43:09.309222Z",
     "shell.execute_reply": "2025-08-16T10:43:09.308410Z",
     "shell.execute_reply.started": "2025-08-16T10:43:09.264306Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:43:11.244279Z",
     "iopub.status.busy": "2025-08-16T10:43:11.243574Z",
     "iopub.status.idle": "2025-08-16T10:43:13.086434Z",
     "shell.execute_reply": "2025-08-16T10:43:13.085667Z",
     "shell.execute_reply.started": "2025-08-16T10:43:11.244250Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Applying Decision Tree Classification model\n",
    "\n",
    "decision_tree_classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 27) # Here we are using the methode of entropy\n",
    "decision_tree_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:43:15.548125Z",
     "iopub.status.busy": "2025-08-16T10:43:15.547533Z",
     "iopub.status.idle": "2025-08-16T10:43:15.615851Z",
     "shell.execute_reply": "2025-08-16T10:43:15.615034Z",
     "shell.execute_reply.started": "2025-08-16T10:43:15.548078Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = decision_tree_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:43:17.607442Z",
     "iopub.status.busy": "2025-08-16T10:43:17.607184Z",
     "iopub.status.idle": "2025-08-16T10:43:17.636791Z",
     "shell.execute_reply": "2025-08-16T10:43:17.636076Z",
     "shell.execute_reply.started": "2025-08-16T10:43:17.607424Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy, precision, and recall of the model\n",
    "\n",
    "decision_tree_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_accuracy['Decision Tree'] = decision_tree_accuracy\n",
    "\n",
    "decision_tree_precision = round(100 * precision_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_precision['Decision Tree'] = decision_tree_precision\n",
    "\n",
    "decision_tree_recall = round(100 * recall_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_recall['Decision Tree'] = decision_tree_recall\n",
    "\n",
    "print('The accuracy of this model is {} %.'.format(decision_tree_accuracy))\n",
    "print('The precision of this model is {} %.'.format(decision_tree_precision))\n",
    "print('The recall of this model is {} %.'.format(decision_tree_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.9 Applying Random Forest Classification (10 trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:43:21.719834Z",
     "iopub.status.busy": "2025-08-16T10:43:21.719542Z",
     "iopub.status.idle": "2025-08-16T10:43:21.842045Z",
     "shell.execute_reply": "2025-08-16T10:43:21.840972Z",
     "shell.execute_reply.started": "2025-08-16T10:43:21.719815Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.880Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# To store error rates\n",
    "error_rates = []\n",
    "\n",
    "# Loop through possible n_estimators values\n",
    "for n in range(10, 201, 10):  # from 10 to 200 with step 10\n",
    "    rf = RandomForestClassifier(n_estimators=n, random_state=42)\n",
    "    rf.fit(X_train, Y_train)\n",
    "    Y_pred = rf.predict(X_test)\n",
    "    error_rates.append(1 - accuracy_score(Y_test, Y_pred))\n",
    "\n",
    "# Find optimal n_estimators\n",
    "n_values = list(range(10, 201, 10))\n",
    "optimal_n = n_values[error_rates.index(min(error_rates))]\n",
    "#print(\"Optimal n_estimators is:\", optimal_n)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_values, error_rates, color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=8)\n",
    "\n",
    "# Add vertical red line at optimal point\n",
    "plt.axvline(x=optimal_n, color='red', linestyle='--', label=f'Optimal n_estimators = {optimal_n}')\n",
    "\n",
    "plt.xlabel('Number of Trees (n_estimators)')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.title('Error Rate vs n_estimators in Random Forest')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.880Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Applying Random Forest Classification model (10 trees)\n",
    "\n",
    "random_forest_10_classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 27)\n",
    "random_forest_10_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.880Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = random_forest_10_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.880Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy, precision, and recall of the model\n",
    "\n",
    "random_forest_10_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_accuracy['Random Forest (10 trees)'] = random_forest_10_accuracy\n",
    "\n",
    "random_forest_10_precision = round(100 * precision_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_precision['Random Forest (10 trees)'] = random_forest_10_precision\n",
    "\n",
    "random_forest_10_recall = round(100 * recall_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_recall['Random Forest (10 trees)'] = random_forest_10_recall\n",
    "\n",
    "print('The accuracy of this model is {} %.'.format(random_forest_10_accuracy))\n",
    "print('The precision of this model is {} %.'.format(random_forest_10_precision))\n",
    "print('The recall of this model is {} %.'.format(random_forest_10_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.10 Applying Random Forest Classification (50 trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.880Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Applying Random Forest Classification model (50 trees)\n",
    "\n",
    "random_forest_50_classifier = RandomForestClassifier(n_estimators = 50, criterion = 'entropy', random_state = 27)\n",
    "random_forest_50_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.880Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = random_forest_50_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.880Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy, precision, and recall of the model\n",
    "\n",
    "random_forest_50_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_accuracy['Random Forest (50 trees)'] = random_forest_50_accuracy\n",
    "\n",
    "random_forest_50_precision = round(100 * precision_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_precision['Random Forest (50 trees)'] = random_forest_50_precision\n",
    "\n",
    "random_forest_50_recall = round(100 * recall_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_recall['Random Forest (50 trees)'] = random_forest_50_recall\n",
    "\n",
    "print('The accuracy of this model is {} %.'.format(random_forest_50_accuracy))\n",
    "print('The precision of this model is {} %.'.format(random_forest_50_precision))\n",
    "print('The recall of this model is {} %.'.format(random_forest_50_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.11 Applying Random Forest Classification (100 trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Applying Random Forest Classification model (100 trees)\n",
    "\n",
    "random_forest_100_classifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 27)\n",
    "random_forest_100_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = random_forest_100_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy, precision, and recall of the model\n",
    "\n",
    "random_forest_100_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_accuracy['Random Forest (100 trees)'] = random_forest_100_accuracy\n",
    "\n",
    "random_forest_100_precision = round(100 * precision_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_precision['Random Forest (100 trees)'] = random_forest_100_precision\n",
    "\n",
    "random_forest_100_recall = round(100 * recall_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_recall['Random Forest (100 trees)'] = random_forest_100_recall\n",
    "\n",
    "print('The accuracy of this model is {} %.'.format(random_forest_100_accuracy))\n",
    "print('The precision of this model is {} %.'.format(random_forest_100_precision))\n",
    "print('The recall of this model is {} %.'.format(random_forest_100_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.12 Applying Random Forest Classification (190 trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:43:40.455270Z",
     "iopub.status.busy": "2025-08-16T10:43:40.453357Z",
     "iopub.status.idle": "2025-08-16T10:44:20.153878Z",
     "shell.execute_reply": "2025-08-16T10:44:20.152894Z",
     "shell.execute_reply.started": "2025-08-16T10:43:40.455203Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Applying Random Forest Classification model (190 trees)\n",
    "\n",
    "random_forest_190_classifier = RandomForestClassifier(n_estimators = 190, criterion = 'entropy', random_state = 27)\n",
    "random_forest_190_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:44:20.155694Z",
     "iopub.status.busy": "2025-08-16T10:44:20.155401Z",
     "iopub.status.idle": "2025-08-16T10:44:21.415316Z",
     "shell.execute_reply": "2025-08-16T10:44:21.414453Z",
     "shell.execute_reply.started": "2025-08-16T10:44:20.155675Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = random_forest_190_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:44:21.416580Z",
     "iopub.status.busy": "2025-08-16T10:44:21.416172Z",
     "iopub.status.idle": "2025-08-16T10:44:21.447246Z",
     "shell.execute_reply": "2025-08-16T10:44:21.446421Z",
     "shell.execute_reply.started": "2025-08-16T10:44:21.416557Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy, precision, and recall of the model\n",
    "\n",
    "random_forest_190_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_accuracy['Random Forest (190 trees)'] = random_forest_190_accuracy\n",
    "\n",
    "random_forest_190_precision = round(100 * precision_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_precision['Random Forest (190 trees)'] = random_forest_190_precision\n",
    "\n",
    "random_forest_190_recall = round(100 * recall_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_recall['Random Forest (190 trees)'] = random_forest_190_recall\n",
    "\n",
    "print('The accuracy of this model is {} %.'.format(random_forest_190_accuracy))\n",
    "print('The precision of this model is {} %.'.format(random_forest_190_precision))\n",
    "print('The recall of this model is {} %.'.format(random_forest_190_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.13 Applying Random Forest Classification (200 trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Applying Random Forest Classification model (200 trees)\n",
    "\n",
    "random_forest_200_classifier = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = 27)\n",
    "random_forest_200_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.881Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = random_forest_200_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.882Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy, precision, and recall of the model\n",
    "\n",
    "random_forest_200_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_accuracy['Random Forest (200 trees)'] = random_forest_200_accuracy\n",
    "\n",
    "random_forest_200_precision = round(100 * precision_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_precision['Random Forest (200 trees)'] = random_forest_200_precision\n",
    "\n",
    "random_forest_200_recall = round(100 * recall_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_recall['Random Forest (200 trees)'] = random_forest_200_recall\n",
    "\n",
    "print('The accuracy of this model is {} %.'.format(random_forest_200_accuracy))\n",
    "print('The precision of this model is {} %.'.format(random_forest_200_precision))\n",
    "print('The recall of this model is {} %.'.format(random_forest_200_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-08-15T12:30:59.882Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Looking at the accuracy graph of all the Random Forest\n",
    "\n",
    "labels = ['10', '50', '100', '190', '200']\n",
    "values = [\n",
    "    random_forest_10_accuracy,\n",
    "    random_forest_50_accuracy,\n",
    "    random_forest_100_accuracy,\n",
    "    random_forest_190_accuracy,\n",
    "    random_forest_200_accuracy\n",
    "]\n",
    "\n",
    "plt.title('Accuracies of all the Random Forest models')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.plot(labels, values, '*-')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By doing above all those thing and exploring we get best n_estimator is `200` also we can see in the above diagram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since 190 and 200 give nearly identical accuracy (difference of just 0.03%), choosing 190 makes sense because:\n",
    "\n",
    "\n",
    "* You reduce computation time (fewer trees to train and predict).\n",
    "\n",
    "\n",
    "* You reduce noise â€” adding more trees beyond a certain point rarely changes accuracy much, but it can make the model slightly more sensitive to tiny fluctuations in the dataset.\n",
    "\n",
    "\n",
    "* From a practical point of view, both are statistically the same â€” the tiny difference could just be due to the randomness in your train-test split.\n",
    "\n",
    "\n",
    "So, picking 190 is a perfectly reasonable and efficient choice here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.13 Applying Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:44:39.030362Z",
     "iopub.status.busy": "2025-08-16T10:44:39.030056Z",
     "iopub.status.idle": "2025-08-16T10:44:39.035831Z",
     "shell.execute_reply": "2025-08-16T10:44:39.035034Z",
     "shell.execute_reply.started": "2025-08-16T10:44:39.030338Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T12:43:58.549925Z",
     "iopub.status.busy": "2025-08-15T12:43:58.549603Z",
     "iopub.status.idle": "2025-08-15T12:43:58.692730Z",
     "shell.execute_reply": "2025-08-15T12:43:58.691606Z",
     "shell.execute_reply.started": "2025-08-15T12:43:58.549901Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('The accuracy of this model logistic_accuracy is {} %.'.format(logistic_accuracy))\n",
    "print('The accuracy of this model nn4_accuracy is {} %.'.format(nn4_accuracy))\n",
    "print('The accuracy of this model naive_bayes_accuracy is {} %.'.format(naive_bayes_accuracy))\n",
    "print('The accuracy of this model decision_tree_accuracy is {} %.'.format(decision_tree_accuracy))\n",
    "print('The accuracy of this model random_forest_190_accuracy is {} %.'.format(random_forest_190_accuracy))\n",
    "print('The accuracy of this model svm_accuracy is {} %.'.format(svm_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:44:52.946883Z",
     "iopub.status.busy": "2025-08-16T10:44:52.946593Z",
     "iopub.status.idle": "2025-08-16T10:44:52.951729Z",
     "shell.execute_reply": "2025-08-16T10:44:52.950871Z",
     "shell.execute_reply.started": "2025-08-16T10:44:52.946864Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Preparing the Stacking Classifier\n",
    "\n",
    "### Define the base models\n",
    "\n",
    "base_models = list()\n",
    "\n",
    "base_models.append(('4nn', classifier_4nn))\n",
    "base_models.append(('decision_tree', decision_tree_classifier))\n",
    "base_models.append(('random_forest_190', random_forest_190_classifier))\n",
    "\n",
    "### Define the meta models\n",
    "\n",
    "meta_model = logistic_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:44:59.098174Z",
     "iopub.status.busy": "2025-08-16T10:44:59.097884Z",
     "iopub.status.idle": "2025-08-16T10:48:47.719795Z",
     "shell.execute_reply": "2025-08-16T10:48:47.719094Z",
     "shell.execute_reply.started": "2025-08-16T10:44:59.098151Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Applying Stacking Classification\n",
    "\n",
    "stacking_classifier = StackingClassifier(estimators = base_models, final_estimator = meta_model)\n",
    "stacking_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:48:47.721069Z",
     "iopub.status.busy": "2025-08-16T10:48:47.720817Z",
     "iopub.status.idle": "2025-08-16T10:48:53.460065Z",
     "shell.execute_reply": "2025-08-16T10:48:53.459174Z",
     "shell.execute_reply.started": "2025-08-16T10:48:47.721048Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = stacking_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:48:53.461306Z",
     "iopub.status.busy": "2025-08-16T10:48:53.461028Z",
     "iopub.status.idle": "2025-08-16T10:48:53.490813Z",
     "shell.execute_reply": "2025-08-16T10:48:53.489879Z",
     "shell.execute_reply.started": "2025-08-16T10:48:53.461284Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy, precision, and recall of the model\n",
    "\n",
    "stacking_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_accuracy['Stacking Classification'] = stacking_accuracy\n",
    "\n",
    "stacking_precision = round(100 * precision_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_precision['Stacking Classification'] = stacking_precision\n",
    "\n",
    "stacking_recall = round(100 * recall_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_recall['Stacking Classification'] = stacking_recall\n",
    "\n",
    "print('The accuracy of this model is {} %.'.format(stacking_accuracy))\n",
    "print('The precision of this model is {} %.'.format(stacking_precision))\n",
    "print('The recall of this model is {} %.'.format(stacking_recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T12:49:09.648195Z",
     "iopub.status.busy": "2025-08-15T12:49:09.647841Z",
     "iopub.status.idle": "2025-08-15T12:49:09.652896Z",
     "shell.execute_reply": "2025-08-15T12:49:09.651838Z",
     "shell.execute_reply.started": "2025-08-15T12:49:09.648166Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-15T12:49:32.138573Z",
     "iopub.status.busy": "2025-08-15T12:49:32.138233Z",
     "iopub.status.idle": "2025-08-15T12:49:33.812358Z",
     "shell.execute_reply": "2025-08-15T12:49:33.811491Z",
     "shell.execute_reply.started": "2025-08-15T12:49:32.138549Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# # Assume 'stacking_classifier' is your already trained model object\n",
    "\n",
    "# # 1. Define the filename for your model\n",
    "# filename = 'stacking_model.pkl'\n",
    "\n",
    "# # 2. Open the file in write-binary ('wb') mode and save the model\n",
    "# with open(filename, 'wb') as file:\n",
    "#     pickle.dump(stacking_classifier, file)\n",
    "\n",
    "# print(f\"Model saved successfully to '{filename}' âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2.14 Applying Soft Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:49:35.077595Z",
     "iopub.status.busy": "2025-08-16T10:49:35.077252Z",
     "iopub.status.idle": "2025-08-16T10:49:35.081683Z",
     "shell.execute_reply": "2025-08-16T10:49:35.080878Z",
     "shell.execute_reply.started": "2025-08-16T10:49:35.077551Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:49:36.828700Z",
     "iopub.status.busy": "2025-08-16T10:49:36.828375Z",
     "iopub.status.idle": "2025-08-16T10:49:36.833353Z",
     "shell.execute_reply": "2025-08-16T10:49:36.832549Z",
     "shell.execute_reply.started": "2025-08-16T10:49:36.828675Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Preparing the Soft Voting Classifier\n",
    "\n",
    "### Creating the list of estimators\n",
    "\n",
    "estimators = list()\n",
    "\n",
    "estimators.append(('4nn', classifier_4nn))\n",
    "estimators.append(('decision_tree', decision_tree_classifier))\n",
    "estimators.append(('random_forest_190', random_forest_190_classifier))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:49:38.360787Z",
     "iopub.status.busy": "2025-08-16T10:49:38.360022Z",
     "iopub.status.idle": "2025-08-16T10:50:20.132554Z",
     "shell.execute_reply": "2025-08-16T10:50:20.131753Z",
     "shell.execute_reply.started": "2025-08-16T10:49:38.360759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Applying Soft Voting Classification\n",
    "\n",
    "soft_voting_classifier = VotingClassifier(estimators = estimators, voting = 'soft')\n",
    "soft_voting_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:50:20.134492Z",
     "iopub.status.busy": "2025-08-16T10:50:20.134151Z",
     "iopub.status.idle": "2025-08-16T10:50:25.793094Z",
     "shell.execute_reply": "2025-08-16T10:50:25.792170Z",
     "shell.execute_reply.started": "2025-08-16T10:50:20.134444Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Predicting the Test set results\n",
    "\n",
    "Y_pred = soft_voting_classifier.predict(X_test)\n",
    "print(np.concatenate((Y_pred.reshape(len(Y_pred), 1), Y_test.reshape(len(Y_test), 1)), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:50:25.794211Z",
     "iopub.status.busy": "2025-08-16T10:50:25.793955Z",
     "iopub.status.idle": "2025-08-16T10:50:25.824032Z",
     "shell.execute_reply": "2025-08-16T10:50:25.823190Z",
     "shell.execute_reply.started": "2025-08-16T10:50:25.794187Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Making the confusion matrix\n",
    "\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "\n",
    "### Printing the accuracy, precision, and recall of the model\n",
    "\n",
    "soft_voting_accuracy = round(100 * accuracy_score(Y_test, Y_pred), 2)\n",
    "model_accuracy['Soft Voting'] = soft_voting_accuracy\n",
    "\n",
    "soft_voting_precision = round(100 * precision_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_precision['Soft Voting'] = soft_voting_precision\n",
    "\n",
    "soft_voting_recall = round(100 * recall_score(Y_test, Y_pred, average = 'weighted'), 2)\n",
    "model_recall['Soft Voting'] = soft_voting_recall\n",
    "\n",
    "print('The accuracy of this model is {} %.'.format(soft_voting_accuracy))\n",
    "print('The precision of this model is {} %.'.format(soft_voting_precision))\n",
    "print('The recall of this model is {} %.'.format(soft_voting_recall))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3 Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation is the process of using different evaluation metrics to understand a machine learning model's performance, as well as its strengths and weaknesses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3.1 Training accuracy of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will tabulate all the models along with their accuracies. This data is stored in the model_performance dictionary. We will use the tabulate package for tabulating the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:50:54.138973Z",
     "iopub.status.busy": "2025-08-16T10:50:54.138675Z",
     "iopub.status.idle": "2025-08-16T10:50:54.145508Z",
     "shell.execute_reply": "2025-08-16T10:50:54.144745Z",
     "shell.execute_reply.started": "2025-08-16T10:50:54.138951Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Looking at the model accuracy dictionary\n",
    "\n",
    "model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:50:56.073396Z",
     "iopub.status.busy": "2025-08-16T10:50:56.072934Z",
     "iopub.status.idle": "2025-08-16T10:50:56.078641Z",
     "shell.execute_reply": "2025-08-16T10:50:56.077820Z",
     "shell.execute_reply.started": "2025-08-16T10:50:56.073371Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Looking at the model precision dictionary\n",
    "\n",
    "model_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:50:57.768373Z",
     "iopub.status.busy": "2025-08-16T10:50:57.768084Z",
     "iopub.status.idle": "2025-08-16T10:50:57.773845Z",
     "shell.execute_reply": "2025-08-16T10:50:57.773163Z",
     "shell.execute_reply.started": "2025-08-16T10:50:57.768350Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Looking at the model recall dictionary\n",
    "\n",
    "model_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:50:59.679338Z",
     "iopub.status.busy": "2025-08-16T10:50:59.679041Z",
     "iopub.status.idle": "2025-08-16T10:50:59.710249Z",
     "shell.execute_reply": "2025-08-16T10:50:59.709184Z",
     "shell.execute_reply.started": "2025-08-16T10:50:59.679314Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-16T10:51:00.892926Z",
     "iopub.status.busy": "2025-08-16T10:51:00.892303Z",
     "iopub.status.idle": "2025-08-16T10:51:00.901229Z",
     "shell.execute_reply": "2025-08-16T10:51:00.900513Z",
     "shell.execute_reply.started": "2025-08-16T10:51:00.892899Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "### Tabulating the results\n",
    "\n",
    "table = []\n",
    "table.append(['S.No.', 'Classification Model', 'Model Accuracy', 'Model Precision', 'Model Recall'])\n",
    "count = 1\n",
    "\n",
    "for model in model_accuracy:\n",
    "    row = [count, model, model_accuracy[model], model_precision[model], model_recall[model]]\n",
    "    table.append(row)\n",
    "    count += 1\n",
    "    \n",
    "print(tabulate(table, headers = 'firstrow', tablefmt = 'fancy_grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above table, we can see that Stacking Classifier has the highest model accuracy of 81.53% among all the other models. It also has the highest precision and recall with 81.5% and 81.53%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence our recommended model - Stacking Classifier provides a model accuracy of 81.53 percent, a model precision of 81.5 percent, and a model recall of 81.53 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 2289007,
     "sourceId": 3846912,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
